{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using TensorBoard with PyTorch**\n",
    "\n",
    "#### **Before You Start**\n",
    "\n",
    "To run this tutorial, you'll need to install PyTorch, TorchVision, Matplotlib, and TensorBoard.\n",
    "With `conda`:\n",
    "\n",
    "`conda install pytorch torchvision -c pytorch` `conda install matplotlib tensorboard`\n",
    "\n",
    "With `pip`:\n",
    "\n",
    "`pip install torch torchvision matplotlib tensorboard`\n",
    "\n",
    "Once the dependencies are installed, restart this notebook in the Python environment where you installed them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Introduction**\n",
    "\n",
    "In this notebook, we'll be training a variant of LeNet-5 against the Fashion-MNIST dataset. Fashion-MNIST is a set of image tiles depicting various garments, with fen class labels indicating the type of garment depicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch model and training necessities import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch Tensorboard support\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Showing Images in TensorBoard**\n",
    "\n",
    "Let's start by adding sample images from our dataset to TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather datasets and prepare them for consumption\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), # 將 PIL 影像或 NumPy 陣列轉換為張量格式，並將像素值縮放至 [0, 1] 範圍內。\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])\n",
    "     # 對資料進行標準化，將像素值調整到 [-1, 1] 範圍內，\n",
    "     # 具體操作是對每個像素減去均值 0.5，然後再除以標準差 0.5。\n",
    "\n",
    "# 資料集的準備\n",
    "# Store separate training and validation splits in ./data\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "        train=True, # 下載訓練資料\n",
    "        download=True, # 若本地無資料，則下載網路資料\n",
    "        transform=transform)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform)\n",
    "training_loader = torch.utils.data.DataLoader(training_set,\n",
    "        batch_size=4, # 每次輸入 4 張圖片\n",
    "        shuffle=True, # 每次迭代前打亂資料，確保模型不會過度擬合\n",
    "        num_workers=2) # 使用 2 個子進程加載資料\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=2)\n",
    "\n",
    "# Class labels for FashionMNIST，10種類別標籤\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`img = img.mean(dim=0)`，將圖片 img 沿著指定的維度進行均值運算。  \n",
    "圖片通常表示為一個三維的張量（Tensor），其維度順序為 (C, H, W)，表示通道數（Channels）、高度（Height）和寬度（Width）。  \n",
    "RGB 彩色圖像，C=3，對應紅、綠、藍三個通道。  \n",
    "`mean(dim=0)`，指的是沿著 C 這個維度，也就是通道維度，對所有通道進行平均。這樣做的結果是將原本多通道的圖像轉換為單通道灰度圖像。  \n",
    "$Gray(h,w)=\\frac{Red(h,w)+Green(h,w)+Blue(h,w)}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for inline images display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0) # 將圖片轉換為單通道。\n",
    "    img = img / 2 + 0.5 # 反歸一化(unnormalize)回原始的值範圍，方便進行顯示。\n",
    "    npimg = img.numpy() # 將張量轉換為 NumPy 陣列，以便於 matplotlib 進行顯示。\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap='Greys') # 如果是單通道圖片，使用灰度圖顯示 (cmap='Greys')。\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 從 training_loader 中提取一批次的圖像\n",
    "# Extract a batch of 4 images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and display them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used TorchVision and Matplotlib to create a visual grid of a minibatch of our input data. Below, we use the `add_image()` call on `SummaryWriter` to log the image for consumption by TensorBoard, and we also call `flush()` to make sure it's written to disk right away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `SummaryWriter` 是 PyTorch 中用來與 TensorBoard 進行交互的類別。  \n",
    "* `SummaryWriter('runs/fashion_mnist_experiment_1')` 創建了一個 `SummaryWriter` 實例，並將日誌數據寫入到 `runs/fashion_mnist_experiment_1` 目錄下。這個目錄用於存放 TensorBoard 的日誌文件，方便之後可視化模型的訓練過程。  \n",
    "* 默認情況下，`log_dir` 參數的值是 `runs`，但這裡我們指定了路徑 `fashion_mnist_experiment_1`。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `add_image` 方法將一張圖像寫入到 TensorBoard 中。  \n",
    "* `four_fashion_mnist_images` 是這次記錄的名稱標籤，你可以用它來標識這次寫入的圖像。  \n",
    "* `img_grid` 是先前生成的包含 4 張 Fashion MNIST 圖像的網格。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default log_dir argument is \"run\" - but it's good to be specific\n",
    "# torch.utils.tensorboard.SummaryWriter is imported above\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "# Write the image data to TensorBoard log dir\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "writer.flush() # 強制將所有緩存的內容寫入到磁盤，確保數據不會因緩存而丟失。\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "# tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you start TensorBoard at the command line and open it in a new browser tab (usually at localhost:6006), you should see the image grid under the IMAGES tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Graphing Scalars to Visualize Training**\n",
    "\n",
    "TensorBoard is useful for tracking the progress and efficacy of your training. Below, we'll run a training loop, track some metrics, and save the data for TensorBoard's consumption.\n",
    "\n",
    "Let's define a model to categorize our image tiles, and an optimizer and loss function for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss() # 使用交叉熵損失函數，進行多分類問題的分類。\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # 使用隨機梯度下降（SGD）作為優化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`view` 是 PyTorch 中的函數，它用來改變張量的形狀而不改變其數據本身。  \n",
    "* -1: 這是自動推導的維度。PyTorch 會根據張量的總元素數量和其他給定的維度，計算出 -1 應該是多少，以保證形狀的正確性。在這裡，-1 將會被計算為 B，即批次大小。\n",
    "* 16 * 4 * 4: 這裡指定了每個樣本的扁平化特徵向量的長度，16 是通道數，4 和 4 是特徵圖的高度和寬度。乘積 16 * 4 * 4 表示每個樣本在展平成一維向量後的總長度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a single epoch, and evaluate the training vs. validation set losses every 1000 batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "Batch(1000\n",
      "Batch(2000\n",
      "Batch(3000\n",
      "Batch(4000\n",
      "Batch(5000\n",
      "Batch(6000\n",
      "Batch(7000\n",
      "Batch(8000\n",
      "Batch(9000\n",
      "Batch(10000\n",
      "Batch(11000\n",
      "Batch(12000\n",
      "Batch(13000\n",
      "Batch(14000\n",
      "Batch(15000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_loader)) # 檢查驗證資料集被分成了多少個 mini-batches。\n",
    "# 這個迴圈表示模型將會在整個訓練資料集上訓練 1 次（即一個 epoch）。\n",
    "for epoch in range(1): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # 對訓練資料集的每一個 mini-batch 進行操作\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        # basic training loop\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad() # 清除累積的梯度（在 PyTorch 中，梯度會累積，這一步確保每次更新都是針對當前 mini-batch 的）。\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels) # 使用損失函數 criterion 計算預測輸出與真實標籤之間的損失。\n",
    "        loss.backward() # 使用反向傳播計算梯度。\n",
    "        optimizer.step() # 更新模型參數。\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999: # Every 1000 mini-batches...\n",
    "            print('Batch({}'.format(i + 1))\n",
    "            # check against the validation set\n",
    "            running_vloss = 0.0\n",
    "\n",
    "            net.train(False) # Don't need to track gradients for validation\n",
    "            for j, vdata in enumerate(validation_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = net(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            net.train(True) # Turn gradient tracking back on for training\n",
    "\n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(validation_loader)\n",
    "\n",
    "            # Log the running loss avgeraged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                    {'Training' : avg_loss, 'Validation' : avg_vloss},\n",
    "                    epoch * len(training_loader) + i)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to your open TensorBoard and have a look at the SCALARS tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualizing Your Model**  \n",
    "TensorBoard can also be used to examine the data flow within your model. To do this, call the `add_graph()` method with a model and sample input. When \n",
    "you open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, grab a single mini-batch of images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph\n",
    "writer.add_graph(net, images)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you switch over to TensorBoard, you should see a GRAPHS tab. Double-click the 'NET\" node to see the layers and data flow within your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualizing Your Dataset with Embeddings**  \n",
    "The 28-by-28 image tiles we're using can be modeled as 784-dimensional vectors (28 * 28 = 784). It can be instructive to project this to a lower-dimensional\n",
    "representation. The `add_embedding()` method will project a set of data onto the three dimensions with highest variance, and display them as an interactive 3D chart. The `add_embedding()` method does this automatically by projecting to the three dimensions with highest variance.\n",
    "Below, we'll take a sample of our data, and generate such an embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# Select a random subset of images and corresponding labels\n",
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# Extract a random subset of data\n",
    "images, labels = select_n_random(training_set.data, training_set.targets)\n",
    "\n",
    "# Get the class labels for the random subset\n",
    "class_labels = [classes[label] for label in labels]\n",
    "\n",
    "#log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "        metadata=class_labels,\n",
    "        label_img=images.unsqueeze(1))\n",
    "\n",
    "writer.flush() # Flush the writer to ensure all data is written to disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you switch to TensorBoard and select the PROJECTOR tab, you should see a 3D representation of the projection. You can rotate and zoom the model.  \n",
    "Examine it at large and small scales, and see whether you can spot patterns in the projected data and the clustering of labels.\n",
    "\n",
    "**Note:** For better visibility, it's recommended to:  \n",
    "* Select \"label\" from the \"Color by\" drop-down on the left\n",
    "* Toggle the Night Mode icon along the top to place the light-colored images on a dark background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Other Resources**\n",
    "For more information, have a look at:\n",
    "* PyTorch documentation on `torch.utils.tensorboard.SummaryWriter` on PyTorch.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
