{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building Models in PyTorch**\n",
    "#### **`torch.nn.Module` and `torch.nn.Parameter`**\n",
    "In this video, we'll be discussing some of the tools PyTorch makes available for building deep learning networks.\n",
    "\n",
    "Except for `Parameter`, the classes we discuss in this video are all subclasses of `torch.nn.Module`. This is the PyTorch base class meant to encapsulate behaviors specific to PyTorch Models and their components.\n",
    "\n",
    "One important behavior of `torch.nn.Module` is registering parameters. If a particular `Module` subclass has learning weights, these weights are expressed as instances of `torch.nn.Parameter`. The `Parameter` class is a subclass of `torch.Tensor`, with the special behavior that when they are assigned as attributes of a `Module`, they are added to the list of that modules parameters. These parameters may be accessed through the `parameters()` method on the `Module` class.\n",
    "\n",
    "* torch.nn.Module: PyTorch 中所有模型和層的基礎類，具有自動註冊參數的能力。\n",
    "* torch.nn.Parameter: torch.Tensor 的子類，專門用來作為模型的可學習參數，當賦值為 Module 的屬性時會自動註冊為模型參數。\n",
    "\n",
    "As a simple example, here's a very simple model with two linear layers and an activation function. We'll create an instance of it and ask it to report on its parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model;\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[-3.205977e-02,  7.872678e-03,  5.418869e-02,  ...,  2.005448e-02, -1.961485e-03, -4.266337e-03],\n",
      "        [-7.094987e-02,  6.961019e-02,  9.257927e-02,  ..., -2.706629e-02,  8.440390e-03,  3.588381e-02],\n",
      "        [-4.440714e-02,  7.478767e-02,  8.611829e-02,  ..., -4.279068e-02, -3.451542e-02, -9.934898e-02],\n",
      "        ...,\n",
      "        [-4.254567e-02,  9.226108e-02,  7.768998e-02,  ...,  8.669520e-02,  2.285053e-02, -1.314601e-02],\n",
      "        [ 3.112680e-02, -1.330163e-02,  5.061924e-05,  ..., -1.745600e-02,  5.860174e-02,  1.716904e-02],\n",
      "        [-4.400945e-02,  3.008768e-03,  3.419369e-04,  ...,  4.247188e-02, -7.746973e-02,  5.233642e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.042655,  0.027361, -0.034678,  0.052504, -0.007222,  0.030691, -0.044026, -0.096724, -0.093869,  0.052892, -0.085523, -0.030717, -0.025077,  0.047264, -0.019173,  0.034067,  0.055910,\n",
      "         0.008219,  0.020504,  0.040760,  0.072656,  0.011833,  0.056866,  0.007950,  0.009493,  0.018558, -0.056187, -0.084007,  0.024355,  0.007976,  0.072948, -0.032041, -0.001662,  0.014619,\n",
      "         0.015207,  0.090236, -0.052455,  0.071097,  0.042391, -0.022411, -0.017308,  0.012913,  0.062911, -0.066232,  0.089819, -0.030221, -0.052309,  0.032015,  0.098814, -0.091862, -0.096077,\n",
      "         0.007928,  0.007766, -0.030338, -0.020755,  0.094255,  0.086633,  0.073894, -0.062545, -0.013620, -0.062432, -0.041334,  0.000143, -0.063273, -0.043984,  0.085020, -0.056202,  0.091792,\n",
      "        -0.059152, -0.091322,  0.083616, -0.045031,  0.073905,  0.009559, -0.060565,  0.031179,  0.088914,  0.014943, -0.061934,  0.063334, -0.040580, -0.049374, -0.006696, -0.090234, -0.065805,\n",
      "        -0.029758,  0.091666, -0.023171,  0.095858,  0.038213,  0.032356,  0.053005, -0.062915, -0.034738, -0.017774, -0.071130, -0.073473, -0.047065, -0.097737,  0.098801,  0.089418, -0.057848,\n",
      "         0.062394, -0.016620,  0.066113,  0.089429,  0.007588,  0.065886, -0.062447,  0.002452,  0.003394,  0.063984,  0.061435, -0.045206, -0.043630,  0.026855,  0.001093,  0.001744,  0.083811,\n",
      "         0.006370,  0.083408, -0.085101,  0.061646, -0.068467,  0.053714, -0.033480, -0.048560,  0.043831,  0.090652, -0.011874,  0.038292,  0.060132, -0.060047,  0.029759, -0.078411,  0.017240,\n",
      "        -0.047336, -0.030710,  0.089705,  0.069854, -0.097118, -0.073899,  0.022835, -0.080533,  0.025506,  0.048338,  0.077033,  0.066360, -0.027291,  0.068085,  0.032353, -0.029871, -0.057543,\n",
      "        -0.073141, -0.085471,  0.053369,  0.048505,  0.079566,  0.095437, -0.019379,  0.092460,  0.063131,  0.080037,  0.043946, -0.092546, -0.029354, -0.002029, -0.039593,  0.000734,  0.082988,\n",
      "         0.052937, -0.081504,  0.024464, -0.071011,  0.081976, -0.084461,  0.080074, -0.036533, -0.061096, -0.016467,  0.097918,  0.073331, -0.058162,  0.021562,  0.037203,  0.077408, -0.019384,\n",
      "        -0.064501,  0.013474,  0.094520,  0.000648,  0.023630,  0.025337,  0.034731, -0.094601,  0.027088, -0.005387, -0.078529, -0.064059,  0.015514], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.111084e-02, -4.634479e-02,  6.630661e-02, -3.842104e-02,  4.439062e-02,  4.022816e-02,  2.789465e-02, -4.231772e-02,  5.071748e-02, -7.502645e-03,  6.565910e-02,  3.229786e-02,\n",
      "         -1.759642e-02,  1.500440e-02,  5.970987e-02,  5.954408e-02,  7.021507e-02,  1.554382e-02,  1.805983e-03,  1.822797e-02, -6.589428e-02,  6.373986e-02,  4.007392e-02,  4.253054e-02,\n",
      "          6.686648e-02,  3.891350e-02, -3.276326e-03,  2.062830e-02,  1.550544e-02,  1.854443e-02,  4.154245e-02,  2.643003e-02, -5.524199e-02,  1.577526e-03,  2.299778e-03, -5.929215e-02,\n",
      "          5.227581e-02,  3.171305e-02,  8.321702e-04, -5.879216e-03,  2.541846e-02, -3.934086e-02,  5.785532e-02, -4.733748e-02, -5.197331e-02,  3.300965e-03,  2.267584e-02,  7.024436e-02,\n",
      "         -5.090716e-02,  3.950556e-02,  6.585068e-02, -6.127947e-02, -4.269056e-02, -5.443872e-02,  4.673342e-02,  2.439105e-02, -2.250876e-02, -4.379713e-02,  6.684632e-02,  2.906355e-02,\n",
      "         -5.748772e-02,  2.106115e-03,  4.957696e-02, -4.640367e-02,  6.884407e-02,  4.111917e-02, -6.548774e-02, -7.582784e-03, -2.364112e-02, -3.117505e-02, -3.091101e-02, -4.011771e-02,\n",
      "          3.768384e-03,  3.593524e-02,  2.787232e-03, -1.742754e-02, -1.584848e-02, -4.553943e-02,  2.820775e-02,  3.955431e-03, -5.626374e-02, -5.773756e-02, -1.352493e-02, -5.904387e-02,\n",
      "         -8.005574e-04,  6.445933e-02, -3.792672e-02, -5.297740e-02,  5.961929e-02,  5.741853e-02,  5.734619e-02,  4.219994e-02,  6.917050e-02,  1.398511e-02, -6.388009e-02,  1.143481e-02,\n",
      "         -1.832114e-02,  4.358200e-02, -2.440800e-02, -2.844281e-03,  1.216599e-02,  5.596479e-02, -3.444633e-02,  2.321529e-02, -3.681923e-02,  2.728795e-02, -3.166500e-02,  3.429580e-02,\n",
      "         -4.888215e-02,  2.401291e-02,  3.713761e-02,  3.996875e-02,  8.065708e-03, -5.891610e-02, -3.735796e-03, -1.235379e-02, -4.334116e-02, -1.763098e-03, -5.353619e-02,  3.400618e-02,\n",
      "          6.494126e-02,  2.255061e-02,  1.463749e-02, -5.030360e-02,  1.808074e-02,  5.772021e-02, -1.266934e-02, -3.737920e-02, -2.997795e-02,  3.032129e-02,  5.617093e-02,  6.802811e-02,\n",
      "          1.837326e-02, -6.945941e-02, -5.724300e-02,  5.204090e-02, -3.560057e-02,  6.980490e-02,  4.762740e-02,  6.823694e-02,  2.561424e-02,  7.974140e-03,  2.348362e-02, -6.441490e-02,\n",
      "          3.419428e-02, -1.876448e-02, -5.599965e-02,  5.913334e-02, -3.032550e-02,  2.283099e-02, -4.860006e-02,  1.220923e-02, -1.756018e-02,  3.421181e-02,  2.263609e-02,  5.462289e-03,\n",
      "          2.934724e-02,  3.970556e-03,  5.268722e-02,  4.217907e-02,  6.924442e-02, -5.090818e-02, -1.582030e-02,  4.778200e-02,  6.902310e-02,  4.976384e-02,  6.086901e-03, -2.669007e-02,\n",
      "          3.097156e-02,  5.604454e-02,  1.393026e-02,  6.725872e-02, -7.539533e-03,  4.956903e-02, -5.916140e-02, -2.737171e-02, -1.946577e-02,  4.087894e-02, -5.170197e-02, -2.777284e-02,\n",
      "          1.017793e-02, -3.526835e-02, -1.436080e-02,  6.892385e-02,  3.599029e-02,  3.178703e-02,  4.773612e-02, -1.559329e-02,  5.042180e-02, -2.221829e-02,  1.063667e-03,  1.757810e-02,\n",
      "         -3.888873e-02,  2.345360e-02,  5.645640e-03, -5.592433e-02,  4.247590e-02, -3.905733e-02,  6.919379e-02, -1.707836e-02],\n",
      "        [ 6.161457e-02, -4.191581e-02, -3.713080e-02,  1.060952e-02,  4.163650e-02,  2.607115e-02, -6.631866e-02, -6.828878e-02,  5.654318e-02, -1.262983e-02,  1.925836e-02, -3.827667e-02,\n",
      "          2.314961e-02,  4.811058e-02,  3.014683e-02,  4.712543e-02, -5.126029e-03,  4.932962e-02, -1.538014e-02, -6.810585e-02,  5.874291e-03,  1.157694e-02,  3.680184e-02,  1.470378e-02,\n",
      "         -6.391008e-02, -6.124388e-02,  3.540533e-02,  3.060591e-02, -5.526938e-03, -2.922241e-02,  6.688835e-02,  4.982877e-02, -4.701166e-02, -1.849893e-02,  3.312124e-02, -1.119606e-02,\n",
      "         -5.922877e-02,  2.534012e-02, -1.432011e-02,  1.601873e-02,  1.632556e-02,  5.242606e-02,  6.559122e-02,  7.043935e-03, -6.137000e-02, -5.347537e-02, -5.058801e-02,  2.593215e-02,\n",
      "          6.154678e-02,  4.854313e-02, -5.379014e-02, -6.270177e-02,  6.182713e-02, -6.379348e-02, -7.686973e-03,  1.612715e-03,  4.414070e-02, -3.152057e-02, -4.108502e-02,  4.309776e-02,\n",
      "          3.901403e-02,  5.219775e-02,  1.547018e-02, -1.624765e-02,  4.120916e-02,  2.400676e-02, -6.363893e-02,  4.933026e-02, -1.275693e-02, -5.850478e-02,  5.267780e-02, -2.280710e-02,\n",
      "          4.517668e-02,  1.909457e-03,  6.706508e-02, -1.040935e-02,  5.715487e-02,  5.355936e-02, -2.258785e-02, -1.964150e-02,  6.752678e-02,  2.724881e-02, -6.804130e-02,  5.902380e-02,\n",
      "          2.721946e-02, -6.705058e-02,  5.856698e-02, -6.936232e-02,  6.422419e-02, -1.699351e-03, -5.600054e-02,  1.964808e-03,  6.980326e-02,  5.285047e-03, -5.896657e-02,  3.854103e-02,\n",
      "          4.699871e-02,  4.032566e-02, -2.398709e-02,  3.223866e-05,  6.425553e-02, -1.056895e-03, -6.783514e-02,  4.087111e-02,  1.561507e-02, -5.943933e-02,  4.373378e-02,  6.707431e-02,\n",
      "          6.937098e-02, -5.307152e-02, -2.871327e-02, -2.902063e-02, -2.218494e-02, -5.032353e-03, -6.096866e-02, -6.318498e-02, -3.778020e-02,  6.003327e-02, -5.966943e-02, -7.314056e-03,\n",
      "         -2.162172e-02, -1.169981e-02,  9.428844e-03, -3.304557e-02,  4.894207e-02,  2.068304e-02, -2.782519e-02, -1.645893e-03,  6.802747e-02, -3.851659e-02, -6.801505e-02,  6.521223e-02,\n",
      "         -7.579744e-03,  2.563857e-02, -6.310863e-02,  4.981294e-03,  6.184145e-02, -6.155286e-02,  5.349183e-02,  2.484661e-02, -1.155959e-02, -9.551048e-03, -6.419855e-02, -1.794757e-02,\n",
      "          5.083448e-02, -6.078347e-02,  1.986036e-02, -4.840381e-03, -2.708203e-02,  1.843899e-03, -4.487412e-02,  6.350770e-02,  3.253914e-03,  2.739785e-02,  6.121898e-02,  2.938932e-02,\n",
      "          2.856113e-03, -4.667019e-02, -5.663539e-02, -9.114292e-03, -4.164759e-02, -6.406846e-02, -4.286157e-02,  2.401245e-02, -6.098143e-02, -1.688235e-02,  4.680902e-03, -6.160891e-02,\n",
      "         -3.757372e-02, -4.270846e-02, -2.795095e-02,  6.259800e-02,  4.958247e-02, -6.670655e-02, -7.725030e-03, -2.014133e-02, -2.701224e-02, -5.332524e-02, -3.677189e-02, -8.996502e-04,\n",
      "         -6.181835e-02,  1.269260e-02, -1.103168e-02, -4.685510e-02, -4.348751e-02, -2.536968e-02,  4.316910e-02,  3.714526e-02,  4.033864e-03,  5.521198e-02, -1.417644e-02, -1.378703e-02,\n",
      "          7.031981e-02,  2.304959e-02, -6.497069e-02,  3.882612e-02, -4.788502e-02, -2.806389e-02, -5.583474e-02, -5.978553e-02],\n",
      "        [-1.028717e-02, -6.616302e-02, -5.244686e-02,  5.063591e-02,  1.843210e-02, -4.135091e-02, -1.277729e-02, -1.315407e-02,  6.833089e-02, -5.720094e-02,  1.361813e-02,  6.567917e-02,\n",
      "         -3.704312e-02,  1.673911e-02,  5.074854e-02, -4.280582e-02,  5.744962e-02, -3.972235e-02, -5.917159e-02,  2.641755e-02,  3.369336e-02,  4.486036e-02,  5.055416e-02,  5.845498e-02,\n",
      "         -2.753460e-02, -3.952724e-02,  4.337423e-02, -2.726087e-02, -5.934529e-03,  2.552733e-03, -4.954584e-02,  4.117323e-02,  3.233563e-02, -5.925053e-02,  5.068076e-02, -2.001080e-02,\n",
      "          2.790482e-02, -2.643115e-02,  4.495198e-02,  1.494992e-02, -4.093903e-02, -5.384843e-02, -2.641534e-02,  2.999997e-02, -1.911862e-02, -5.391977e-02,  3.251621e-02,  2.156741e-02,\n",
      "         -3.561438e-02, -3.484743e-02, -2.822286e-02,  2.744259e-02,  2.880439e-02,  2.129868e-03,  2.711379e-02,  8.397736e-03,  4.489936e-02,  2.120087e-02,  1.312765e-02,  4.335627e-02,\n",
      "         -2.502152e-02, -7.619187e-03,  5.170684e-02,  4.642554e-03,  9.401627e-03,  1.714400e-02,  5.450123e-02, -2.697751e-02, -3.167767e-02,  6.793387e-03,  1.187182e-02,  3.367510e-02,\n",
      "          4.080293e-02, -5.060999e-02,  2.917163e-02, -5.007856e-03,  9.393767e-03,  9.674340e-03, -1.408905e-03, -6.864353e-02, -2.706836e-02,  4.776085e-02, -4.412489e-02,  6.920398e-02,\n",
      "          5.978493e-02,  5.322179e-02, -7.052472e-02,  3.338425e-02,  1.678597e-02, -6.193174e-02, -2.451741e-02, -4.893121e-02,  2.279069e-02,  5.028260e-02, -7.593833e-03,  6.927244e-02,\n",
      "          1.301610e-02, -4.563271e-02,  6.645242e-02,  5.046489e-02, -6.077310e-02, -2.540514e-02, -2.894574e-02, -1.142673e-02, -8.264069e-03, -4.820250e-02,  6.311574e-02, -2.973834e-02,\n",
      "          1.511469e-03, -2.856961e-02,  3.068313e-03,  2.258866e-02,  2.210157e-02,  1.457240e-02,  2.965729e-02, -8.017488e-03,  6.436466e-02, -2.659804e-02,  4.632948e-02,  1.304585e-02,\n",
      "          1.429204e-02, -5.250417e-03,  2.720983e-02, -5.695535e-02, -2.783276e-03,  5.985404e-02,  9.822287e-03, -1.225330e-02,  7.912010e-03, -2.909729e-02,  3.606296e-02, -7.514864e-03,\n",
      "         -4.319894e-02, -1.410962e-02, -6.570255e-02,  5.857579e-03, -1.234366e-02, -3.402671e-02,  3.888258e-02,  6.908635e-02,  2.531957e-02,  2.133682e-02,  1.386890e-02, -2.476469e-02,\n",
      "         -1.542568e-02,  2.510539e-02, -3.122845e-02,  5.001161e-02, -2.062745e-03, -8.841027e-03, -1.017461e-02,  5.712535e-02,  4.333277e-02, -3.200182e-02,  4.912511e-02,  1.206350e-02,\n",
      "          4.460447e-03, -5.924871e-02,  6.822529e-02,  6.915390e-02, -6.993271e-02,  4.524674e-02, -1.969572e-02,  1.169261e-02, -5.748687e-02,  5.645901e-03,  3.549093e-02,  3.960367e-02,\n",
      "         -3.887720e-02, -1.242302e-03,  3.546517e-02, -2.158028e-02,  6.116584e-03,  1.382869e-02,  7.660836e-03, -3.757761e-02,  3.578191e-02,  5.465729e-02,  2.182838e-02,  7.826209e-03,\n",
      "         -3.766640e-02, -6.779245e-02,  3.526352e-03, -5.068776e-02, -3.035777e-02, -4.221433e-02,  1.657480e-02,  3.859152e-02,  4.536287e-02,  1.131806e-02, -5.808204e-03,  4.478604e-02,\n",
      "         -1.746254e-02,  3.789201e-02, -9.188723e-03, -4.484887e-02, -3.713867e-02,  5.277863e-02, -4.981142e-02, -4.871481e-02],\n",
      "        [ 4.157797e-02, -1.731482e-02, -2.326101e-02,  1.054795e-02, -5.337914e-02,  2.842872e-02, -9.958651e-03, -2.723879e-02, -3.940205e-02, -1.049417e-02,  5.163518e-02,  2.411890e-02,\n",
      "          2.950991e-02, -4.655823e-02, -5.840180e-02, -8.253634e-03, -3.348427e-02, -5.171200e-02,  3.839067e-02, -1.518684e-02, -5.731363e-02, -6.496987e-02,  5.714042e-02, -5.052274e-02,\n",
      "          6.363397e-02,  7.042795e-03, -4.968291e-02, -4.283660e-02,  1.293670e-02,  2.218238e-02,  5.898537e-02, -1.147225e-02,  3.189895e-02, -3.549710e-02, -6.856169e-02,  3.163624e-02,\n",
      "         -5.702943e-03,  3.863432e-02,  1.169021e-02, -4.164163e-02,  4.869507e-02, -6.298989e-02,  5.411604e-02,  2.219301e-02, -3.691986e-03,  4.502150e-02, -2.572336e-02, -4.588511e-02,\n",
      "         -2.881347e-02,  3.117603e-02, -4.449965e-02,  6.569117e-03,  1.620129e-02,  2.685653e-02,  4.538058e-02, -3.995121e-03, -5.298740e-02, -1.269585e-02,  5.238602e-02,  6.991606e-02,\n",
      "         -6.440958e-02, -1.707726e-02,  6.231504e-02,  3.313348e-03, -1.154529e-02, -6.400101e-03, -3.462392e-02,  3.086215e-02, -3.669857e-02, -6.027339e-02,  6.510786e-02, -1.298728e-02,\n",
      "         -2.273776e-03,  3.810871e-02, -2.458790e-02,  4.975519e-02, -6.190114e-02, -1.824623e-02,  6.305493e-02,  4.168663e-02,  6.193831e-02, -1.333573e-02,  5.622260e-03,  3.816945e-02,\n",
      "         -4.127494e-02,  3.929087e-02, -6.362192e-03, -5.997488e-02,  2.912477e-02, -5.639472e-02, -4.538561e-02,  6.679975e-02,  6.870434e-02,  4.370228e-02,  2.559831e-02,  4.694571e-02,\n",
      "          1.514581e-02,  3.665056e-02, -2.496174e-02, -5.960258e-02,  4.490069e-02,  6.369650e-02,  2.321605e-02, -6.814051e-02, -1.433993e-02,  1.032206e-02, -1.894696e-02,  2.342917e-03,\n",
      "         -6.594872e-02,  4.412986e-03, -2.564252e-02,  6.379003e-02, -2.769650e-02,  4.796762e-02, -5.591482e-03,  1.063059e-02,  2.894349e-03,  2.809840e-02,  5.968008e-02,  2.523537e-02,\n",
      "         -3.444617e-02,  3.928766e-03,  5.532067e-02, -6.490730e-02, -6.440702e-02,  1.081093e-02, -3.405194e-02, -3.725916e-02, -8.191392e-04, -8.968934e-03,  2.524994e-02,  4.202734e-02,\n",
      "          4.213129e-02, -1.113757e-03,  6.316252e-03,  3.635947e-02,  5.638573e-02, -1.625781e-02, -4.855572e-02, -6.343077e-02, -6.871267e-02, -4.387836e-02,  3.901868e-02, -3.521492e-02,\n",
      "         -3.886700e-02, -7.013213e-02, -3.672615e-04,  5.088717e-02, -5.359666e-02, -5.377449e-03, -2.197419e-02,  4.479516e-02, -4.130827e-02,  5.513378e-02, -6.286919e-03, -3.393938e-02,\n",
      "          2.740327e-02, -5.269557e-02,  2.512728e-02,  4.290976e-02, -6.384447e-03, -5.663700e-03,  2.481816e-02, -3.713667e-02,  1.176540e-02, -1.950960e-02, -1.427349e-02,  3.254969e-02,\n",
      "         -7.916056e-03, -5.134435e-02, -6.819268e-02,  3.755257e-03,  2.663764e-02,  3.208563e-02, -9.075575e-03,  2.314653e-02,  6.222910e-02,  3.933817e-03,  2.793325e-02,  5.757330e-02,\n",
      "         -1.456276e-03,  1.191746e-02, -2.821952e-02, -6.237796e-02, -3.055160e-02,  6.648722e-02, -6.549954e-02, -5.698188e-02, -2.007140e-02,  4.622810e-03, -3.932729e-02, -4.836053e-03,\n",
      "          2.353696e-02,  3.524080e-02,  3.591219e-02,  8.390427e-03,  3.429557e-02, -5.779393e-03, -6.492110e-02, -5.534649e-03],\n",
      "        [ 2.976757e-02,  8.392669e-03,  8.571014e-03, -4.645295e-02, -2.373508e-02, -2.836796e-02, -5.120939e-02,  2.344642e-02,  9.328015e-03, -6.778630e-02,  1.926869e-02, -1.213116e-02,\n",
      "         -8.691736e-03,  2.148046e-02,  4.764620e-02, -6.091794e-02, -1.680820e-02, -4.811677e-02,  4.892999e-02,  3.583618e-02, -1.853870e-02,  2.223355e-02,  5.649403e-02, -8.931756e-04,\n",
      "          6.152459e-02,  6.504268e-02, -4.954220e-02,  5.263235e-02,  1.208522e-02,  1.804252e-02,  1.986372e-02,  6.107666e-02, -6.456370e-02, -4.338527e-02,  4.930437e-02, -4.507508e-02,\n",
      "         -1.525082e-03, -4.406097e-02, -6.253602e-02, -4.860332e-02,  1.858104e-02,  6.828123e-02,  7.360950e-03, -2.580443e-02, -2.447821e-03, -2.415726e-02, -6.506145e-02, -6.127591e-02,\n",
      "         -3.343642e-03,  3.594214e-02, -4.999279e-02,  6.651907e-02, -5.524392e-02, -3.347129e-03,  7.660210e-03, -4.655427e-02, -6.910086e-03,  7.645473e-03,  1.222932e-02,  2.766455e-02,\n",
      "          4.718381e-02, -5.168399e-02,  1.383237e-02,  8.671910e-03, -3.391137e-02, -2.929572e-02, -1.389221e-02,  6.034086e-02, -4.047199e-02,  6.967176e-02, -6.742100e-02,  4.727893e-02,\n",
      "         -4.210655e-02,  2.008673e-02, -1.233915e-02, -1.648271e-02, -6.243642e-02, -6.879134e-02, -8.261912e-03,  8.357860e-03,  5.644266e-02,  3.854125e-02, -3.870015e-02,  4.595661e-02,\n",
      "         -4.742138e-02,  2.354748e-02, -4.447739e-02,  5.254378e-02,  1.524770e-02,  4.946142e-02,  1.593307e-02, -2.933034e-02, -1.954851e-02,  3.697643e-02,  4.094368e-02,  1.949938e-02,\n",
      "          5.398430e-02,  6.316399e-02,  4.602738e-03,  6.397888e-04,  4.905676e-02,  1.552330e-02,  2.165021e-02,  1.500881e-02,  4.409716e-03, -1.685382e-02,  5.210156e-02,  2.374910e-03,\n",
      "         -3.263447e-02, -2.448520e-02, -2.773532e-02,  6.840634e-02, -6.719034e-02,  4.655481e-02, -5.271378e-02,  5.531891e-02, -5.213206e-02, -5.475304e-02,  6.241823e-02, -4.124396e-03,\n",
      "          3.376911e-02, -5.812198e-02,  1.539499e-03,  2.591609e-02,  5.551787e-02,  2.021172e-02, -3.086639e-02,  3.587390e-02, -2.327624e-02, -5.006581e-02,  4.422423e-02,  3.726476e-02,\n",
      "         -4.376359e-02, -6.624763e-02,  6.432255e-02,  5.078944e-02,  6.130493e-02,  3.521014e-02, -5.795111e-02,  2.520582e-02, -5.488366e-03, -6.199969e-02,  1.708391e-02,  1.667516e-02,\n",
      "         -6.644251e-02, -2.220396e-02, -2.822733e-02, -1.937743e-02, -2.011236e-02, -1.841813e-02, -5.882199e-02, -3.526660e-02,  6.017057e-02,  2.016606e-02,  7.560872e-03, -4.938854e-02,\n",
      "          3.581737e-02, -3.326686e-02,  6.487263e-02, -6.501059e-02, -6.333008e-02,  8.661278e-03, -2.083798e-02,  3.855765e-03, -3.912238e-02,  6.956268e-02,  5.493409e-02, -5.270466e-03,\n",
      "         -5.831938e-02, -1.499638e-02, -3.518241e-02, -5.941649e-02,  1.076905e-02,  2.333906e-02,  3.448131e-02, -8.461494e-03, -5.561908e-02,  1.537203e-02,  5.883833e-02,  4.252141e-02,\n",
      "          3.612278e-02,  1.064096e-02,  5.465963e-02,  3.407133e-02,  3.130615e-02,  6.574810e-02,  6.275622e-02, -5.640924e-03,  1.213688e-02,  6.719470e-03, -3.779990e-02, -4.445226e-02,\n",
      "         -6.727751e-02, -3.550325e-02, -3.147631e-02,  5.001009e-02, -6.292586e-02, -3.433422e-02,  3.953040e-02, -3.251313e-02],\n",
      "        [ 6.098140e-02, -1.260054e-02,  6.198633e-02,  6.779894e-03, -6.501831e-02,  6.104424e-02,  3.598322e-02, -5.333745e-02, -9.946059e-03,  6.851377e-02, -1.833336e-02, -4.616090e-02,\n",
      "         -5.751979e-02,  1.679087e-02, -8.866519e-03, -5.409531e-02, -2.658672e-02, -6.588819e-02,  2.704561e-03,  3.880921e-02, -1.874629e-02,  6.384278e-02, -3.449288e-02, -6.898731e-03,\n",
      "          6.040040e-02,  2.617345e-02,  4.815576e-02, -8.703213e-03,  2.358926e-02,  2.323532e-02, -1.118778e-02,  3.355297e-02, -1.521360e-02, -1.724585e-02, -3.965206e-02,  1.797672e-02,\n",
      "         -6.327064e-02, -2.430572e-02, -2.342584e-02, -3.339216e-02, -3.757175e-02, -5.227934e-02, -5.146948e-02,  2.360607e-02,  7.458009e-03,  2.131633e-02,  5.840655e-02,  3.215154e-02,\n",
      "          5.305934e-02, -1.734311e-02, -3.318110e-02,  3.056871e-02, -3.059657e-02,  8.672304e-03, -1.201441e-02,  4.666653e-02,  3.610413e-02,  3.698020e-02,  4.559179e-02, -2.126205e-02,\n",
      "         -3.965333e-03,  1.196191e-02,  5.975591e-02, -5.533356e-02,  6.278830e-02, -4.959517e-02,  3.798615e-02, -1.006035e-02, -4.756952e-02, -8.552287e-03,  5.593900e-02,  3.211769e-02,\n",
      "         -4.272764e-02, -6.057435e-02,  6.923056e-02,  5.813838e-02, -5.777907e-02,  6.399646e-02,  4.770003e-03, -3.889285e-02,  3.620883e-02, -4.918979e-02, -3.970491e-02, -4.273492e-02,\n",
      "         -1.352131e-04,  1.569918e-02,  6.924699e-02, -3.084430e-02, -6.220215e-02, -4.199550e-02,  2.710437e-02,  5.046726e-02,  9.800442e-03, -3.783676e-02, -9.156596e-03, -9.538583e-03,\n",
      "         -6.313138e-02, -3.453881e-02, -2.673822e-02,  4.542300e-02, -4.690386e-02,  6.732062e-02, -1.345170e-02,  6.850482e-02, -3.092093e-02, -1.814357e-02, -1.887757e-02, -3.566616e-02,\n",
      "          6.289929e-04, -4.471634e-02,  4.146198e-02,  5.358294e-02, -4.408015e-02,  6.134128e-02, -1.039604e-02,  4.267359e-02,  9.973317e-03,  3.810138e-02,  5.936458e-02, -5.655548e-02,\n",
      "         -2.480780e-02,  3.407257e-02,  2.030499e-03,  1.320691e-02,  6.926353e-02,  5.890235e-02, -3.652547e-02,  9.398669e-03, -1.331417e-02,  2.628298e-02,  4.667632e-02,  2.778619e-02,\n",
      "         -1.286244e-02,  6.447309e-02,  2.572750e-02,  5.727217e-02,  5.900740e-02,  1.451752e-02, -5.375358e-02, -4.710203e-02,  6.326487e-02,  2.911292e-03,  4.121516e-02,  3.102951e-02,\n",
      "          9.262770e-03,  4.496840e-02, -2.285026e-03,  5.168357e-02,  3.071226e-02, -6.395177e-02, -3.151122e-02,  3.914966e-02, -5.798560e-02,  6.001682e-02, -5.914167e-02,  6.262017e-02,\n",
      "         -4.624560e-02,  1.277541e-02, -3.770269e-03, -1.716878e-02,  6.903233e-02, -3.055990e-03, -7.508025e-04, -8.413497e-03,  5.021425e-02, -2.143680e-02, -2.788380e-02, -2.398409e-03,\n",
      "          2.755710e-02,  5.516708e-04, -1.015775e-02,  9.371147e-03, -6.568653e-02, -6.131547e-02,  3.843190e-02, -7.171199e-03, -3.690362e-02,  6.888630e-02,  4.936501e-02,  1.606563e-02,\n",
      "         -1.605818e-02,  4.549485e-02, -1.391847e-02, -2.282658e-02,  2.157854e-02, -3.863720e-02, -4.041597e-02,  5.629905e-02, -4.883225e-02, -6.107750e-02,  6.335781e-02, -2.364136e-02,\n",
      "          6.134353e-02, -2.868661e-02, -2.077023e-02, -5.810317e-02, -1.044335e-02, -4.911842e-02, -5.081842e-02, -2.875742e-02],\n",
      "        [ 3.556728e-02, -5.545589e-02,  4.708000e-02,  6.627212e-02,  6.969262e-02,  1.538642e-03,  3.577124e-02, -5.163842e-02,  6.306130e-02,  2.719235e-02,  4.393522e-02, -3.743281e-02,\n",
      "          1.295335e-02,  5.337289e-02,  6.894418e-02,  4.438289e-02,  5.827861e-02, -4.580766e-04, -1.793594e-02,  1.429909e-02,  4.555658e-02,  2.660512e-02, -1.922369e-02, -5.283768e-02,\n",
      "          1.667164e-03,  5.182503e-02, -4.592275e-02, -3.479685e-02, -2.422996e-03, -6.688019e-02, -6.476296e-02,  6.112208e-02, -2.250862e-02,  6.169321e-02, -5.848334e-02,  3.389702e-02,\n",
      "          5.654305e-03, -3.214001e-02, -6.944360e-02, -3.307769e-02,  6.582063e-02, -5.021064e-02,  4.487342e-02,  5.224827e-02,  6.272713e-02, -7.013322e-02,  5.086356e-02,  5.608471e-02,\n",
      "         -6.392100e-02, -5.216286e-03,  4.800278e-02, -2.503701e-02,  6.317314e-02, -4.522994e-02, -4.838035e-04,  4.966285e-02,  3.222600e-02,  6.599929e-02,  2.023857e-02,  5.672134e-02,\n",
      "         -2.099097e-03, -4.988808e-02, -3.764674e-02,  1.522761e-02,  6.594830e-02,  4.038832e-02,  6.484499e-02,  4.634472e-02, -5.675099e-02, -6.287467e-02, -1.499452e-02,  5.738296e-02,\n",
      "          2.508134e-02,  3.289282e-03, -5.644693e-02,  4.014107e-02,  6.756223e-02,  5.297050e-02,  6.855405e-02, -4.570709e-02, -1.292869e-02, -3.029438e-02, -3.388898e-02,  4.952942e-02,\n",
      "         -3.262501e-02, -6.051185e-02,  1.479986e-02,  5.302929e-02,  3.835998e-02, -6.887545e-02, -7.260233e-03, -5.546066e-02,  2.582049e-02, -4.022109e-02,  5.971903e-02, -2.371002e-02,\n",
      "         -5.909277e-02,  4.152806e-02,  4.226588e-02,  5.976325e-02, -6.799492e-02,  3.457523e-02, -5.110843e-02,  3.921241e-02,  4.534212e-02,  2.091125e-02, -3.970682e-02,  4.796413e-02,\n",
      "         -5.825841e-02,  6.557310e-02, -2.983236e-02,  5.340821e-02,  1.606974e-02,  1.862843e-02,  1.381321e-02,  3.788567e-02, -6.700291e-02,  6.461874e-03,  5.923351e-02,  5.182953e-02,\n",
      "         -9.297814e-03, -3.730774e-02, -1.947857e-03, -5.229565e-02,  2.454475e-03,  6.336943e-02, -4.983874e-02,  4.033074e-02, -5.878975e-02,  1.032890e-02, -8.868709e-03,  2.571455e-02,\n",
      "         -4.995375e-02,  2.787793e-02,  2.681424e-02,  2.697811e-02, -6.634727e-02,  2.679890e-02,  6.391197e-03, -3.435415e-02, -5.381221e-02,  6.700081e-02, -6.575614e-02, -6.922523e-02,\n",
      "         -4.125517e-02,  4.991592e-02,  3.441352e-02,  1.644591e-02, -4.125499e-02, -2.730241e-02, -1.629487e-03,  6.282475e-02, -2.756721e-02,  4.107179e-02,  5.108665e-02, -3.536265e-02,\n",
      "         -1.675883e-02,  1.534519e-02, -4.121251e-02, -7.125653e-03, -3.864432e-02,  5.557909e-02,  6.838761e-03,  1.346253e-03,  6.342789e-02, -2.073653e-03, -2.803777e-02, -1.287260e-02,\n",
      "          5.410991e-02, -1.574474e-02, -7.019185e-02,  6.758281e-02,  3.757328e-04, -5.436403e-02, -5.874657e-02, -1.378827e-03, -1.169806e-02, -1.837167e-02,  3.498718e-03, -3.245565e-02,\n",
      "         -5.074874e-02, -3.883800e-02,  3.177840e-02,  4.679462e-02,  6.227667e-02,  3.601341e-02, -4.241191e-02,  6.006751e-02, -6.326251e-02,  6.545953e-02, -2.894733e-02, -1.616286e-02,\n",
      "          2.947595e-02, -5.008261e-02,  1.937674e-02, -4.269227e-02, -3.713190e-02, -1.224418e-02, -1.770970e-02,  2.905965e-03],\n",
      "        [-2.149257e-02,  1.353994e-04, -4.252287e-02,  2.960473e-02, -1.171054e-02, -8.871239e-03,  1.898271e-02,  1.952755e-02,  5.638249e-03, -5.233291e-02, -1.813652e-02,  5.095213e-02,\n",
      "          1.856827e-02, -1.514292e-02,  3.847780e-02,  1.480864e-02, -4.593547e-02, -3.824377e-02,  5.435757e-02, -1.656544e-02,  1.411051e-03,  6.706799e-02, -5.353443e-02, -1.174682e-02,\n",
      "         -1.549050e-04,  2.354184e-02, -1.235423e-02, -1.989383e-02,  6.912740e-02, -1.867983e-02,  8.389510e-03, -5.120603e-02,  7.951647e-03,  5.656780e-02, -6.768705e-02,  3.376439e-02,\n",
      "          5.726867e-02, -4.805833e-02,  1.829458e-02,  6.870272e-02,  1.556975e-02, -6.239459e-02, -6.447470e-02,  5.078645e-02,  3.635193e-02,  4.882057e-02,  6.177349e-02, -3.271425e-02,\n",
      "          9.484299e-03,  5.260086e-02, -5.416570e-02,  6.576154e-02, -2.392307e-03,  2.354221e-02, -1.142770e-04,  6.177350e-02,  5.483625e-02, -6.278480e-02, -6.545004e-02, -9.553824e-03,\n",
      "          2.938085e-02, -1.164130e-02,  3.270561e-02,  5.789883e-02,  2.495138e-02,  5.360944e-02, -2.588015e-02,  2.527201e-02,  2.021632e-02, -6.536027e-02, -5.019359e-02,  6.815914e-02,\n",
      "          7.641390e-04, -5.388760e-02,  5.896544e-02,  6.119402e-02,  2.162037e-02,  3.757702e-02, -4.692544e-02,  5.325718e-02, -3.646088e-02, -6.756969e-03,  4.075617e-04,  6.891833e-02,\n",
      "         -4.021426e-02,  1.794025e-04, -3.525690e-02,  8.618288e-03,  1.115404e-02,  1.473182e-02,  6.069406e-02, -6.869640e-02, -1.446224e-02,  6.294153e-02,  1.662107e-02,  9.334855e-03,\n",
      "         -3.306473e-02, -6.333812e-02, -6.778951e-02, -5.791545e-02, -3.559981e-02,  4.874366e-02, -1.011067e-02,  5.057272e-02,  2.707428e-02, -5.931152e-02, -6.620575e-02, -4.558581e-02,\n",
      "          6.866204e-02,  4.141243e-02,  6.015439e-02, -1.946948e-02, -5.792989e-02,  4.867356e-02, -1.064900e-02, -3.631791e-02,  2.670990e-02,  4.397114e-02, -4.666168e-02, -6.025793e-02,\n",
      "          1.929693e-03, -2.508513e-02, -5.694006e-02, -3.662623e-03, -1.628233e-02,  6.587618e-02, -1.153384e-02,  4.453471e-02, -1.510451e-02, -8.515250e-03, -1.322843e-02,  5.101430e-02,\n",
      "         -4.216772e-02, -3.359750e-02, -5.895592e-03,  1.795769e-02, -6.207834e-02,  3.057260e-02,  3.552424e-02,  3.853837e-02,  3.853068e-02, -4.877910e-02,  6.351844e-02, -4.004561e-02,\n",
      "          4.375748e-03, -7.650122e-03,  2.598280e-02, -1.058842e-02, -1.620360e-03, -5.873317e-02,  2.753856e-02, -2.088960e-02,  5.428942e-02, -6.866141e-02,  6.412054e-02,  7.734150e-04,\n",
      "         -9.352073e-03,  5.549420e-02, -7.232271e-03,  7.005572e-02, -2.739748e-02, -6.067657e-02,  6.549185e-02,  8.310914e-03,  4.570564e-02,  3.003667e-02, -2.043795e-02,  1.816882e-02,\n",
      "          4.319804e-02,  5.802234e-02, -1.451816e-02, -6.593996e-02,  3.127895e-02,  3.044295e-02, -4.203435e-02,  1.745375e-02,  4.294477e-03,  5.637451e-02, -4.006558e-02, -5.899838e-02,\n",
      "          1.410762e-02,  2.637789e-02, -5.919486e-02, -2.516862e-02, -4.004164e-02,  5.614758e-02, -3.727424e-02,  1.422390e-02,  3.695408e-02, -6.071890e-02,  6.264576e-02,  2.072626e-02,\n",
      "          4.858370e-02,  8.198269e-03,  3.170228e-02,  6.143438e-02, -6.434322e-02, -3.335992e-02, -3.535118e-02, -4.430704e-03],\n",
      "        [-3.019830e-02,  1.410018e-02, -6.737766e-02,  4.619170e-02,  3.811470e-02, -3.803331e-02,  1.953810e-02, -3.693423e-02,  6.734212e-02,  7.007010e-02, -7.223062e-03, -5.590719e-02,\n",
      "         -3.998840e-02, -6.618231e-02,  3.550591e-02, -3.346172e-02,  8.976370e-03,  5.234684e-02, -4.774179e-02, -4.929843e-02,  7.059517e-02, -5.496264e-02,  1.593538e-02, -5.344295e-02,\n",
      "         -2.032697e-02,  6.859227e-02, -5.474597e-03, -3.501922e-04,  5.148720e-02,  1.728062e-02, -2.975103e-02,  3.805036e-02, -6.497571e-02, -5.235869e-02, -6.996943e-02, -3.932245e-02,\n",
      "          2.430863e-02, -3.563103e-02,  1.985442e-02, -7.016199e-02,  4.695766e-02,  5.413687e-02,  2.905802e-02,  9.603225e-03,  4.743288e-02,  5.289438e-02, -3.395049e-02,  6.776889e-02,\n",
      "          3.120025e-02,  6.215014e-03,  3.733471e-02, -1.890401e-02,  1.559513e-02, -8.972064e-04,  3.161408e-02, -1.073540e-02, -3.050008e-02,  3.700740e-02,  5.522818e-02, -4.854679e-03,\n",
      "          3.809676e-02,  5.296919e-02, -7.266462e-03,  3.524895e-02, -2.001273e-02, -6.252594e-03, -6.648090e-02, -6.748360e-02, -3.409892e-02, -2.604008e-02, -3.381844e-02, -6.426372e-03,\n",
      "          3.319198e-02, -6.578848e-03,  2.728345e-02,  2.274065e-02,  5.727042e-02, -3.818549e-03, -2.690431e-02,  3.966500e-02,  3.771092e-02, -2.859242e-02,  6.820176e-02, -6.554133e-02,\n",
      "         -4.992326e-02, -6.259593e-02,  6.368177e-02, -2.711367e-02,  6.719003e-02, -9.851903e-03,  2.374113e-03,  6.704956e-02,  3.429070e-02,  1.021414e-02, -5.155285e-02, -8.372042e-03,\n",
      "          4.265092e-02,  3.929774e-02, -6.678283e-03,  4.071397e-02, -9.556748e-03,  1.428449e-02, -9.030107e-03, -1.716708e-02, -1.450399e-02,  3.273322e-02,  3.324825e-02,  3.100479e-02,\n",
      "          2.335028e-02, -6.857824e-02,  4.319559e-02,  3.335961e-02, -3.499844e-02, -5.713164e-02,  5.785709e-02, -3.940585e-02, -5.667031e-02, -9.606659e-03, -6.889876e-02,  8.340321e-03,\n",
      "         -4.262169e-02,  6.211170e-02,  3.396615e-02, -2.803279e-02,  6.375230e-02,  6.812499e-02,  3.330665e-02, -6.093304e-02, -6.015662e-02, -5.048811e-02,  5.417767e-02,  1.210456e-02,\n",
      "         -6.759155e-02,  1.432087e-02,  3.339791e-02, -2.477071e-02, -5.223540e-02,  2.303923e-02, -3.213530e-02, -5.915777e-02, -2.564687e-02,  3.658939e-02, -4.913083e-02,  1.127242e-02,\n",
      "         -2.913308e-02, -1.728554e-02, -1.810309e-02, -4.565954e-02, -6.231287e-02, -2.172500e-02, -2.846035e-02,  9.053871e-03, -1.620904e-03, -3.160816e-02, -3.237278e-02, -6.182247e-02,\n",
      "          2.541526e-02, -3.861842e-02, -2.591028e-02,  5.736711e-02, -5.854923e-02,  6.847292e-03, -1.543423e-02,  6.670907e-03, -6.215917e-02, -6.971701e-02, -4.435617e-02,  2.404090e-02,\n",
      "          4.441252e-02, -6.961855e-02, -3.620245e-02,  7.129654e-03,  2.253663e-02, -3.469410e-02,  4.541837e-02, -2.575548e-02,  3.253715e-02, -4.790778e-02,  5.124231e-02,  6.172181e-02,\n",
      "         -6.849765e-02, -7.959023e-03,  4.248556e-02, -3.642187e-03,  3.866327e-02,  4.599381e-02,  1.211107e-02, -6.734063e-02, -6.096028e-03, -2.887871e-02,  8.229166e-04,  3.050108e-02,\n",
      "         -4.135486e-02, -2.805920e-02,  3.482760e-02,  1.191963e-02,  6.209166e-02,  3.179336e-02,  1.355100e-02,  5.045980e-04],\n",
      "        [ 3.077880e-02, -2.175815e-02,  3.321599e-02, -5.758882e-02, -1.728178e-02, -6.551470e-02,  4.558053e-02, -5.969480e-02, -9.748820e-03, -3.737488e-02,  5.564908e-02, -3.575534e-02,\n",
      "          3.719785e-02, -7.590897e-03, -1.053998e-02,  4.748737e-02, -5.637180e-02, -4.048633e-02,  2.104414e-02, -6.497057e-02, -2.994015e-02, -2.144568e-02, -1.705438e-03,  2.802253e-03,\n",
      "         -2.966970e-02, -1.977476e-02,  3.821388e-03, -2.065644e-02,  3.644897e-02,  5.707064e-02,  5.939972e-02, -4.995896e-02,  5.041274e-02, -4.569238e-02,  4.103264e-02,  2.884112e-02,\n",
      "          1.171543e-02,  1.555610e-02,  6.469607e-02, -3.964408e-02,  4.346342e-02,  9.629652e-03,  3.883246e-02,  3.526155e-02,  9.740397e-03,  2.831360e-02,  1.990870e-04,  2.151927e-02,\n",
      "         -2.678417e-02, -5.325604e-02, -4.855091e-02,  2.317805e-02, -3.997706e-02,  6.489342e-02,  4.031133e-02, -6.736139e-02, -4.378651e-02, -1.266780e-02,  3.392401e-02, -5.936615e-03,\n",
      "         -4.499162e-02, -2.843857e-02,  1.236878e-02,  1.416317e-02, -1.167391e-02, -1.620493e-02, -5.815680e-02,  2.153830e-02,  3.129137e-02,  1.016902e-02, -6.552406e-03,  4.125438e-02,\n",
      "          5.305531e-02,  1.486982e-02, -5.354755e-03, -6.768572e-02,  3.940074e-02, -7.052433e-02,  6.001458e-02, -6.217835e-02, -3.368785e-02,  3.359340e-03, -6.560171e-02, -2.108109e-02,\n",
      "         -2.839113e-02, -4.504570e-02, -6.450931e-02,  6.430410e-03, -8.784711e-03,  2.681352e-02,  3.760036e-02,  6.476755e-02,  3.332423e-02,  2.696033e-02, -3.789008e-02, -6.304565e-02,\n",
      "          1.344530e-02,  1.007447e-02, -3.287373e-02, -5.722776e-03, -3.285649e-02, -5.411587e-02, -4.485062e-02,  3.441346e-02,  1.803597e-02,  1.587769e-02,  2.059102e-02,  3.190562e-03,\n",
      "          4.923069e-02, -5.216628e-02,  4.464957e-02, -7.385463e-04, -2.534045e-02, -5.601657e-02, -4.982455e-02,  2.472498e-03,  3.363641e-02, -5.801795e-02, -1.883996e-02, -1.569378e-02,\n",
      "          4.043221e-02, -6.140293e-02,  3.466469e-02,  2.500986e-02,  5.413701e-02, -6.920549e-02, -1.348918e-02,  3.461465e-02,  7.016773e-02, -4.723499e-02, -3.806383e-02, -8.943841e-03,\n",
      "         -4.689049e-02,  3.405725e-02, -5.380399e-02,  4.563700e-02, -4.310868e-02, -8.483410e-03, -3.028072e-03,  6.954291e-02,  5.611304e-02, -5.084125e-02,  2.789334e-02, -4.214104e-02,\n",
      "         -2.587438e-02, -6.436877e-03,  4.210713e-02, -1.224615e-02, -3.756635e-03,  4.434882e-02, -3.150968e-02, -3.876837e-02, -3.176442e-02,  5.183320e-02, -6.848754e-02,  2.718766e-02,\n",
      "         -2.594292e-04,  1.927643e-02,  4.675439e-02, -5.018053e-02,  4.865874e-02, -1.943234e-02,  1.181904e-02,  3.945068e-02,  2.311353e-02, -2.343544e-02,  4.454407e-02, -5.358314e-02,\n",
      "         -6.183907e-02,  3.418212e-02, -3.846525e-02, -2.742152e-02, -2.953783e-03,  1.600895e-02,  9.089716e-03,  4.859358e-02,  1.924606e-02,  3.254652e-02, -3.447307e-02,  6.670120e-02,\n",
      "          6.581444e-02,  2.695648e-02, -5.911139e-02, -6.866494e-02,  6.833435e-02,  5.400352e-03,  6.395299e-02,  2.609841e-02, -1.223618e-02, -3.905603e-02, -6.551541e-02, -5.548867e-02,\n",
      "          6.311998e-03,  3.707017e-02, -1.225936e-02, -3.136060e-02, -2.780537e-02,  2.967264e-02,  2.928342e-02, -5.102158e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.027709,  0.042218, -0.063396, -0.052104, -0.061415, -0.034603,  0.050273, -0.032538, -0.038449,  0.015396], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-4.111084e-02, -4.634479e-02,  6.630661e-02, -3.842104e-02,  4.439062e-02,  4.022816e-02,  2.789465e-02, -4.231772e-02,  5.071748e-02, -7.502645e-03,  6.565910e-02,  3.229786e-02,\n",
      "         -1.759642e-02,  1.500440e-02,  5.970987e-02,  5.954408e-02,  7.021507e-02,  1.554382e-02,  1.805983e-03,  1.822797e-02, -6.589428e-02,  6.373986e-02,  4.007392e-02,  4.253054e-02,\n",
      "          6.686648e-02,  3.891350e-02, -3.276326e-03,  2.062830e-02,  1.550544e-02,  1.854443e-02,  4.154245e-02,  2.643003e-02, -5.524199e-02,  1.577526e-03,  2.299778e-03, -5.929215e-02,\n",
      "          5.227581e-02,  3.171305e-02,  8.321702e-04, -5.879216e-03,  2.541846e-02, -3.934086e-02,  5.785532e-02, -4.733748e-02, -5.197331e-02,  3.300965e-03,  2.267584e-02,  7.024436e-02,\n",
      "         -5.090716e-02,  3.950556e-02,  6.585068e-02, -6.127947e-02, -4.269056e-02, -5.443872e-02,  4.673342e-02,  2.439105e-02, -2.250876e-02, -4.379713e-02,  6.684632e-02,  2.906355e-02,\n",
      "         -5.748772e-02,  2.106115e-03,  4.957696e-02, -4.640367e-02,  6.884407e-02,  4.111917e-02, -6.548774e-02, -7.582784e-03, -2.364112e-02, -3.117505e-02, -3.091101e-02, -4.011771e-02,\n",
      "          3.768384e-03,  3.593524e-02,  2.787232e-03, -1.742754e-02, -1.584848e-02, -4.553943e-02,  2.820775e-02,  3.955431e-03, -5.626374e-02, -5.773756e-02, -1.352493e-02, -5.904387e-02,\n",
      "         -8.005574e-04,  6.445933e-02, -3.792672e-02, -5.297740e-02,  5.961929e-02,  5.741853e-02,  5.734619e-02,  4.219994e-02,  6.917050e-02,  1.398511e-02, -6.388009e-02,  1.143481e-02,\n",
      "         -1.832114e-02,  4.358200e-02, -2.440800e-02, -2.844281e-03,  1.216599e-02,  5.596479e-02, -3.444633e-02,  2.321529e-02, -3.681923e-02,  2.728795e-02, -3.166500e-02,  3.429580e-02,\n",
      "         -4.888215e-02,  2.401291e-02,  3.713761e-02,  3.996875e-02,  8.065708e-03, -5.891610e-02, -3.735796e-03, -1.235379e-02, -4.334116e-02, -1.763098e-03, -5.353619e-02,  3.400618e-02,\n",
      "          6.494126e-02,  2.255061e-02,  1.463749e-02, -5.030360e-02,  1.808074e-02,  5.772021e-02, -1.266934e-02, -3.737920e-02, -2.997795e-02,  3.032129e-02,  5.617093e-02,  6.802811e-02,\n",
      "          1.837326e-02, -6.945941e-02, -5.724300e-02,  5.204090e-02, -3.560057e-02,  6.980490e-02,  4.762740e-02,  6.823694e-02,  2.561424e-02,  7.974140e-03,  2.348362e-02, -6.441490e-02,\n",
      "          3.419428e-02, -1.876448e-02, -5.599965e-02,  5.913334e-02, -3.032550e-02,  2.283099e-02, -4.860006e-02,  1.220923e-02, -1.756018e-02,  3.421181e-02,  2.263609e-02,  5.462289e-03,\n",
      "          2.934724e-02,  3.970556e-03,  5.268722e-02,  4.217907e-02,  6.924442e-02, -5.090818e-02, -1.582030e-02,  4.778200e-02,  6.902310e-02,  4.976384e-02,  6.086901e-03, -2.669007e-02,\n",
      "          3.097156e-02,  5.604454e-02,  1.393026e-02,  6.725872e-02, -7.539533e-03,  4.956903e-02, -5.916140e-02, -2.737171e-02, -1.946577e-02,  4.087894e-02, -5.170197e-02, -2.777284e-02,\n",
      "          1.017793e-02, -3.526835e-02, -1.436080e-02,  6.892385e-02,  3.599029e-02,  3.178703e-02,  4.773612e-02, -1.559329e-02,  5.042180e-02, -2.221829e-02,  1.063667e-03,  1.757810e-02,\n",
      "         -3.888873e-02,  2.345360e-02,  5.645640e-03, -5.592433e-02,  4.247590e-02, -3.905733e-02,  6.919379e-02, -1.707836e-02],\n",
      "        [ 6.161457e-02, -4.191581e-02, -3.713080e-02,  1.060952e-02,  4.163650e-02,  2.607115e-02, -6.631866e-02, -6.828878e-02,  5.654318e-02, -1.262983e-02,  1.925836e-02, -3.827667e-02,\n",
      "          2.314961e-02,  4.811058e-02,  3.014683e-02,  4.712543e-02, -5.126029e-03,  4.932962e-02, -1.538014e-02, -6.810585e-02,  5.874291e-03,  1.157694e-02,  3.680184e-02,  1.470378e-02,\n",
      "         -6.391008e-02, -6.124388e-02,  3.540533e-02,  3.060591e-02, -5.526938e-03, -2.922241e-02,  6.688835e-02,  4.982877e-02, -4.701166e-02, -1.849893e-02,  3.312124e-02, -1.119606e-02,\n",
      "         -5.922877e-02,  2.534012e-02, -1.432011e-02,  1.601873e-02,  1.632556e-02,  5.242606e-02,  6.559122e-02,  7.043935e-03, -6.137000e-02, -5.347537e-02, -5.058801e-02,  2.593215e-02,\n",
      "          6.154678e-02,  4.854313e-02, -5.379014e-02, -6.270177e-02,  6.182713e-02, -6.379348e-02, -7.686973e-03,  1.612715e-03,  4.414070e-02, -3.152057e-02, -4.108502e-02,  4.309776e-02,\n",
      "          3.901403e-02,  5.219775e-02,  1.547018e-02, -1.624765e-02,  4.120916e-02,  2.400676e-02, -6.363893e-02,  4.933026e-02, -1.275693e-02, -5.850478e-02,  5.267780e-02, -2.280710e-02,\n",
      "          4.517668e-02,  1.909457e-03,  6.706508e-02, -1.040935e-02,  5.715487e-02,  5.355936e-02, -2.258785e-02, -1.964150e-02,  6.752678e-02,  2.724881e-02, -6.804130e-02,  5.902380e-02,\n",
      "          2.721946e-02, -6.705058e-02,  5.856698e-02, -6.936232e-02,  6.422419e-02, -1.699351e-03, -5.600054e-02,  1.964808e-03,  6.980326e-02,  5.285047e-03, -5.896657e-02,  3.854103e-02,\n",
      "          4.699871e-02,  4.032566e-02, -2.398709e-02,  3.223866e-05,  6.425553e-02, -1.056895e-03, -6.783514e-02,  4.087111e-02,  1.561507e-02, -5.943933e-02,  4.373378e-02,  6.707431e-02,\n",
      "          6.937098e-02, -5.307152e-02, -2.871327e-02, -2.902063e-02, -2.218494e-02, -5.032353e-03, -6.096866e-02, -6.318498e-02, -3.778020e-02,  6.003327e-02, -5.966943e-02, -7.314056e-03,\n",
      "         -2.162172e-02, -1.169981e-02,  9.428844e-03, -3.304557e-02,  4.894207e-02,  2.068304e-02, -2.782519e-02, -1.645893e-03,  6.802747e-02, -3.851659e-02, -6.801505e-02,  6.521223e-02,\n",
      "         -7.579744e-03,  2.563857e-02, -6.310863e-02,  4.981294e-03,  6.184145e-02, -6.155286e-02,  5.349183e-02,  2.484661e-02, -1.155959e-02, -9.551048e-03, -6.419855e-02, -1.794757e-02,\n",
      "          5.083448e-02, -6.078347e-02,  1.986036e-02, -4.840381e-03, -2.708203e-02,  1.843899e-03, -4.487412e-02,  6.350770e-02,  3.253914e-03,  2.739785e-02,  6.121898e-02,  2.938932e-02,\n",
      "          2.856113e-03, -4.667019e-02, -5.663539e-02, -9.114292e-03, -4.164759e-02, -6.406846e-02, -4.286157e-02,  2.401245e-02, -6.098143e-02, -1.688235e-02,  4.680902e-03, -6.160891e-02,\n",
      "         -3.757372e-02, -4.270846e-02, -2.795095e-02,  6.259800e-02,  4.958247e-02, -6.670655e-02, -7.725030e-03, -2.014133e-02, -2.701224e-02, -5.332524e-02, -3.677189e-02, -8.996502e-04,\n",
      "         -6.181835e-02,  1.269260e-02, -1.103168e-02, -4.685510e-02, -4.348751e-02, -2.536968e-02,  4.316910e-02,  3.714526e-02,  4.033864e-03,  5.521198e-02, -1.417644e-02, -1.378703e-02,\n",
      "          7.031981e-02,  2.304959e-02, -6.497069e-02,  3.882612e-02, -4.788502e-02, -2.806389e-02, -5.583474e-02, -5.978553e-02],\n",
      "        [-1.028717e-02, -6.616302e-02, -5.244686e-02,  5.063591e-02,  1.843210e-02, -4.135091e-02, -1.277729e-02, -1.315407e-02,  6.833089e-02, -5.720094e-02,  1.361813e-02,  6.567917e-02,\n",
      "         -3.704312e-02,  1.673911e-02,  5.074854e-02, -4.280582e-02,  5.744962e-02, -3.972235e-02, -5.917159e-02,  2.641755e-02,  3.369336e-02,  4.486036e-02,  5.055416e-02,  5.845498e-02,\n",
      "         -2.753460e-02, -3.952724e-02,  4.337423e-02, -2.726087e-02, -5.934529e-03,  2.552733e-03, -4.954584e-02,  4.117323e-02,  3.233563e-02, -5.925053e-02,  5.068076e-02, -2.001080e-02,\n",
      "          2.790482e-02, -2.643115e-02,  4.495198e-02,  1.494992e-02, -4.093903e-02, -5.384843e-02, -2.641534e-02,  2.999997e-02, -1.911862e-02, -5.391977e-02,  3.251621e-02,  2.156741e-02,\n",
      "         -3.561438e-02, -3.484743e-02, -2.822286e-02,  2.744259e-02,  2.880439e-02,  2.129868e-03,  2.711379e-02,  8.397736e-03,  4.489936e-02,  2.120087e-02,  1.312765e-02,  4.335627e-02,\n",
      "         -2.502152e-02, -7.619187e-03,  5.170684e-02,  4.642554e-03,  9.401627e-03,  1.714400e-02,  5.450123e-02, -2.697751e-02, -3.167767e-02,  6.793387e-03,  1.187182e-02,  3.367510e-02,\n",
      "          4.080293e-02, -5.060999e-02,  2.917163e-02, -5.007856e-03,  9.393767e-03,  9.674340e-03, -1.408905e-03, -6.864353e-02, -2.706836e-02,  4.776085e-02, -4.412489e-02,  6.920398e-02,\n",
      "          5.978493e-02,  5.322179e-02, -7.052472e-02,  3.338425e-02,  1.678597e-02, -6.193174e-02, -2.451741e-02, -4.893121e-02,  2.279069e-02,  5.028260e-02, -7.593833e-03,  6.927244e-02,\n",
      "          1.301610e-02, -4.563271e-02,  6.645242e-02,  5.046489e-02, -6.077310e-02, -2.540514e-02, -2.894574e-02, -1.142673e-02, -8.264069e-03, -4.820250e-02,  6.311574e-02, -2.973834e-02,\n",
      "          1.511469e-03, -2.856961e-02,  3.068313e-03,  2.258866e-02,  2.210157e-02,  1.457240e-02,  2.965729e-02, -8.017488e-03,  6.436466e-02, -2.659804e-02,  4.632948e-02,  1.304585e-02,\n",
      "          1.429204e-02, -5.250417e-03,  2.720983e-02, -5.695535e-02, -2.783276e-03,  5.985404e-02,  9.822287e-03, -1.225330e-02,  7.912010e-03, -2.909729e-02,  3.606296e-02, -7.514864e-03,\n",
      "         -4.319894e-02, -1.410962e-02, -6.570255e-02,  5.857579e-03, -1.234366e-02, -3.402671e-02,  3.888258e-02,  6.908635e-02,  2.531957e-02,  2.133682e-02,  1.386890e-02, -2.476469e-02,\n",
      "         -1.542568e-02,  2.510539e-02, -3.122845e-02,  5.001161e-02, -2.062745e-03, -8.841027e-03, -1.017461e-02,  5.712535e-02,  4.333277e-02, -3.200182e-02,  4.912511e-02,  1.206350e-02,\n",
      "          4.460447e-03, -5.924871e-02,  6.822529e-02,  6.915390e-02, -6.993271e-02,  4.524674e-02, -1.969572e-02,  1.169261e-02, -5.748687e-02,  5.645901e-03,  3.549093e-02,  3.960367e-02,\n",
      "         -3.887720e-02, -1.242302e-03,  3.546517e-02, -2.158028e-02,  6.116584e-03,  1.382869e-02,  7.660836e-03, -3.757761e-02,  3.578191e-02,  5.465729e-02,  2.182838e-02,  7.826209e-03,\n",
      "         -3.766640e-02, -6.779245e-02,  3.526352e-03, -5.068776e-02, -3.035777e-02, -4.221433e-02,  1.657480e-02,  3.859152e-02,  4.536287e-02,  1.131806e-02, -5.808204e-03,  4.478604e-02,\n",
      "         -1.746254e-02,  3.789201e-02, -9.188723e-03, -4.484887e-02, -3.713867e-02,  5.277863e-02, -4.981142e-02, -4.871481e-02],\n",
      "        [ 4.157797e-02, -1.731482e-02, -2.326101e-02,  1.054795e-02, -5.337914e-02,  2.842872e-02, -9.958651e-03, -2.723879e-02, -3.940205e-02, -1.049417e-02,  5.163518e-02,  2.411890e-02,\n",
      "          2.950991e-02, -4.655823e-02, -5.840180e-02, -8.253634e-03, -3.348427e-02, -5.171200e-02,  3.839067e-02, -1.518684e-02, -5.731363e-02, -6.496987e-02,  5.714042e-02, -5.052274e-02,\n",
      "          6.363397e-02,  7.042795e-03, -4.968291e-02, -4.283660e-02,  1.293670e-02,  2.218238e-02,  5.898537e-02, -1.147225e-02,  3.189895e-02, -3.549710e-02, -6.856169e-02,  3.163624e-02,\n",
      "         -5.702943e-03,  3.863432e-02,  1.169021e-02, -4.164163e-02,  4.869507e-02, -6.298989e-02,  5.411604e-02,  2.219301e-02, -3.691986e-03,  4.502150e-02, -2.572336e-02, -4.588511e-02,\n",
      "         -2.881347e-02,  3.117603e-02, -4.449965e-02,  6.569117e-03,  1.620129e-02,  2.685653e-02,  4.538058e-02, -3.995121e-03, -5.298740e-02, -1.269585e-02,  5.238602e-02,  6.991606e-02,\n",
      "         -6.440958e-02, -1.707726e-02,  6.231504e-02,  3.313348e-03, -1.154529e-02, -6.400101e-03, -3.462392e-02,  3.086215e-02, -3.669857e-02, -6.027339e-02,  6.510786e-02, -1.298728e-02,\n",
      "         -2.273776e-03,  3.810871e-02, -2.458790e-02,  4.975519e-02, -6.190114e-02, -1.824623e-02,  6.305493e-02,  4.168663e-02,  6.193831e-02, -1.333573e-02,  5.622260e-03,  3.816945e-02,\n",
      "         -4.127494e-02,  3.929087e-02, -6.362192e-03, -5.997488e-02,  2.912477e-02, -5.639472e-02, -4.538561e-02,  6.679975e-02,  6.870434e-02,  4.370228e-02,  2.559831e-02,  4.694571e-02,\n",
      "          1.514581e-02,  3.665056e-02, -2.496174e-02, -5.960258e-02,  4.490069e-02,  6.369650e-02,  2.321605e-02, -6.814051e-02, -1.433993e-02,  1.032206e-02, -1.894696e-02,  2.342917e-03,\n",
      "         -6.594872e-02,  4.412986e-03, -2.564252e-02,  6.379003e-02, -2.769650e-02,  4.796762e-02, -5.591482e-03,  1.063059e-02,  2.894349e-03,  2.809840e-02,  5.968008e-02,  2.523537e-02,\n",
      "         -3.444617e-02,  3.928766e-03,  5.532067e-02, -6.490730e-02, -6.440702e-02,  1.081093e-02, -3.405194e-02, -3.725916e-02, -8.191392e-04, -8.968934e-03,  2.524994e-02,  4.202734e-02,\n",
      "          4.213129e-02, -1.113757e-03,  6.316252e-03,  3.635947e-02,  5.638573e-02, -1.625781e-02, -4.855572e-02, -6.343077e-02, -6.871267e-02, -4.387836e-02,  3.901868e-02, -3.521492e-02,\n",
      "         -3.886700e-02, -7.013213e-02, -3.672615e-04,  5.088717e-02, -5.359666e-02, -5.377449e-03, -2.197419e-02,  4.479516e-02, -4.130827e-02,  5.513378e-02, -6.286919e-03, -3.393938e-02,\n",
      "          2.740327e-02, -5.269557e-02,  2.512728e-02,  4.290976e-02, -6.384447e-03, -5.663700e-03,  2.481816e-02, -3.713667e-02,  1.176540e-02, -1.950960e-02, -1.427349e-02,  3.254969e-02,\n",
      "         -7.916056e-03, -5.134435e-02, -6.819268e-02,  3.755257e-03,  2.663764e-02,  3.208563e-02, -9.075575e-03,  2.314653e-02,  6.222910e-02,  3.933817e-03,  2.793325e-02,  5.757330e-02,\n",
      "         -1.456276e-03,  1.191746e-02, -2.821952e-02, -6.237796e-02, -3.055160e-02,  6.648722e-02, -6.549954e-02, -5.698188e-02, -2.007140e-02,  4.622810e-03, -3.932729e-02, -4.836053e-03,\n",
      "          2.353696e-02,  3.524080e-02,  3.591219e-02,  8.390427e-03,  3.429557e-02, -5.779393e-03, -6.492110e-02, -5.534649e-03],\n",
      "        [ 2.976757e-02,  8.392669e-03,  8.571014e-03, -4.645295e-02, -2.373508e-02, -2.836796e-02, -5.120939e-02,  2.344642e-02,  9.328015e-03, -6.778630e-02,  1.926869e-02, -1.213116e-02,\n",
      "         -8.691736e-03,  2.148046e-02,  4.764620e-02, -6.091794e-02, -1.680820e-02, -4.811677e-02,  4.892999e-02,  3.583618e-02, -1.853870e-02,  2.223355e-02,  5.649403e-02, -8.931756e-04,\n",
      "          6.152459e-02,  6.504268e-02, -4.954220e-02,  5.263235e-02,  1.208522e-02,  1.804252e-02,  1.986372e-02,  6.107666e-02, -6.456370e-02, -4.338527e-02,  4.930437e-02, -4.507508e-02,\n",
      "         -1.525082e-03, -4.406097e-02, -6.253602e-02, -4.860332e-02,  1.858104e-02,  6.828123e-02,  7.360950e-03, -2.580443e-02, -2.447821e-03, -2.415726e-02, -6.506145e-02, -6.127591e-02,\n",
      "         -3.343642e-03,  3.594214e-02, -4.999279e-02,  6.651907e-02, -5.524392e-02, -3.347129e-03,  7.660210e-03, -4.655427e-02, -6.910086e-03,  7.645473e-03,  1.222932e-02,  2.766455e-02,\n",
      "          4.718381e-02, -5.168399e-02,  1.383237e-02,  8.671910e-03, -3.391137e-02, -2.929572e-02, -1.389221e-02,  6.034086e-02, -4.047199e-02,  6.967176e-02, -6.742100e-02,  4.727893e-02,\n",
      "         -4.210655e-02,  2.008673e-02, -1.233915e-02, -1.648271e-02, -6.243642e-02, -6.879134e-02, -8.261912e-03,  8.357860e-03,  5.644266e-02,  3.854125e-02, -3.870015e-02,  4.595661e-02,\n",
      "         -4.742138e-02,  2.354748e-02, -4.447739e-02,  5.254378e-02,  1.524770e-02,  4.946142e-02,  1.593307e-02, -2.933034e-02, -1.954851e-02,  3.697643e-02,  4.094368e-02,  1.949938e-02,\n",
      "          5.398430e-02,  6.316399e-02,  4.602738e-03,  6.397888e-04,  4.905676e-02,  1.552330e-02,  2.165021e-02,  1.500881e-02,  4.409716e-03, -1.685382e-02,  5.210156e-02,  2.374910e-03,\n",
      "         -3.263447e-02, -2.448520e-02, -2.773532e-02,  6.840634e-02, -6.719034e-02,  4.655481e-02, -5.271378e-02,  5.531891e-02, -5.213206e-02, -5.475304e-02,  6.241823e-02, -4.124396e-03,\n",
      "          3.376911e-02, -5.812198e-02,  1.539499e-03,  2.591609e-02,  5.551787e-02,  2.021172e-02, -3.086639e-02,  3.587390e-02, -2.327624e-02, -5.006581e-02,  4.422423e-02,  3.726476e-02,\n",
      "         -4.376359e-02, -6.624763e-02,  6.432255e-02,  5.078944e-02,  6.130493e-02,  3.521014e-02, -5.795111e-02,  2.520582e-02, -5.488366e-03, -6.199969e-02,  1.708391e-02,  1.667516e-02,\n",
      "         -6.644251e-02, -2.220396e-02, -2.822733e-02, -1.937743e-02, -2.011236e-02, -1.841813e-02, -5.882199e-02, -3.526660e-02,  6.017057e-02,  2.016606e-02,  7.560872e-03, -4.938854e-02,\n",
      "          3.581737e-02, -3.326686e-02,  6.487263e-02, -6.501059e-02, -6.333008e-02,  8.661278e-03, -2.083798e-02,  3.855765e-03, -3.912238e-02,  6.956268e-02,  5.493409e-02, -5.270466e-03,\n",
      "         -5.831938e-02, -1.499638e-02, -3.518241e-02, -5.941649e-02,  1.076905e-02,  2.333906e-02,  3.448131e-02, -8.461494e-03, -5.561908e-02,  1.537203e-02,  5.883833e-02,  4.252141e-02,\n",
      "          3.612278e-02,  1.064096e-02,  5.465963e-02,  3.407133e-02,  3.130615e-02,  6.574810e-02,  6.275622e-02, -5.640924e-03,  1.213688e-02,  6.719470e-03, -3.779990e-02, -4.445226e-02,\n",
      "         -6.727751e-02, -3.550325e-02, -3.147631e-02,  5.001009e-02, -6.292586e-02, -3.433422e-02,  3.953040e-02, -3.251313e-02],\n",
      "        [ 6.098140e-02, -1.260054e-02,  6.198633e-02,  6.779894e-03, -6.501831e-02,  6.104424e-02,  3.598322e-02, -5.333745e-02, -9.946059e-03,  6.851377e-02, -1.833336e-02, -4.616090e-02,\n",
      "         -5.751979e-02,  1.679087e-02, -8.866519e-03, -5.409531e-02, -2.658672e-02, -6.588819e-02,  2.704561e-03,  3.880921e-02, -1.874629e-02,  6.384278e-02, -3.449288e-02, -6.898731e-03,\n",
      "          6.040040e-02,  2.617345e-02,  4.815576e-02, -8.703213e-03,  2.358926e-02,  2.323532e-02, -1.118778e-02,  3.355297e-02, -1.521360e-02, -1.724585e-02, -3.965206e-02,  1.797672e-02,\n",
      "         -6.327064e-02, -2.430572e-02, -2.342584e-02, -3.339216e-02, -3.757175e-02, -5.227934e-02, -5.146948e-02,  2.360607e-02,  7.458009e-03,  2.131633e-02,  5.840655e-02,  3.215154e-02,\n",
      "          5.305934e-02, -1.734311e-02, -3.318110e-02,  3.056871e-02, -3.059657e-02,  8.672304e-03, -1.201441e-02,  4.666653e-02,  3.610413e-02,  3.698020e-02,  4.559179e-02, -2.126205e-02,\n",
      "         -3.965333e-03,  1.196191e-02,  5.975591e-02, -5.533356e-02,  6.278830e-02, -4.959517e-02,  3.798615e-02, -1.006035e-02, -4.756952e-02, -8.552287e-03,  5.593900e-02,  3.211769e-02,\n",
      "         -4.272764e-02, -6.057435e-02,  6.923056e-02,  5.813838e-02, -5.777907e-02,  6.399646e-02,  4.770003e-03, -3.889285e-02,  3.620883e-02, -4.918979e-02, -3.970491e-02, -4.273492e-02,\n",
      "         -1.352131e-04,  1.569918e-02,  6.924699e-02, -3.084430e-02, -6.220215e-02, -4.199550e-02,  2.710437e-02,  5.046726e-02,  9.800442e-03, -3.783676e-02, -9.156596e-03, -9.538583e-03,\n",
      "         -6.313138e-02, -3.453881e-02, -2.673822e-02,  4.542300e-02, -4.690386e-02,  6.732062e-02, -1.345170e-02,  6.850482e-02, -3.092093e-02, -1.814357e-02, -1.887757e-02, -3.566616e-02,\n",
      "          6.289929e-04, -4.471634e-02,  4.146198e-02,  5.358294e-02, -4.408015e-02,  6.134128e-02, -1.039604e-02,  4.267359e-02,  9.973317e-03,  3.810138e-02,  5.936458e-02, -5.655548e-02,\n",
      "         -2.480780e-02,  3.407257e-02,  2.030499e-03,  1.320691e-02,  6.926353e-02,  5.890235e-02, -3.652547e-02,  9.398669e-03, -1.331417e-02,  2.628298e-02,  4.667632e-02,  2.778619e-02,\n",
      "         -1.286244e-02,  6.447309e-02,  2.572750e-02,  5.727217e-02,  5.900740e-02,  1.451752e-02, -5.375358e-02, -4.710203e-02,  6.326487e-02,  2.911292e-03,  4.121516e-02,  3.102951e-02,\n",
      "          9.262770e-03,  4.496840e-02, -2.285026e-03,  5.168357e-02,  3.071226e-02, -6.395177e-02, -3.151122e-02,  3.914966e-02, -5.798560e-02,  6.001682e-02, -5.914167e-02,  6.262017e-02,\n",
      "         -4.624560e-02,  1.277541e-02, -3.770269e-03, -1.716878e-02,  6.903233e-02, -3.055990e-03, -7.508025e-04, -8.413497e-03,  5.021425e-02, -2.143680e-02, -2.788380e-02, -2.398409e-03,\n",
      "          2.755710e-02,  5.516708e-04, -1.015775e-02,  9.371147e-03, -6.568653e-02, -6.131547e-02,  3.843190e-02, -7.171199e-03, -3.690362e-02,  6.888630e-02,  4.936501e-02,  1.606563e-02,\n",
      "         -1.605818e-02,  4.549485e-02, -1.391847e-02, -2.282658e-02,  2.157854e-02, -3.863720e-02, -4.041597e-02,  5.629905e-02, -4.883225e-02, -6.107750e-02,  6.335781e-02, -2.364136e-02,\n",
      "          6.134353e-02, -2.868661e-02, -2.077023e-02, -5.810317e-02, -1.044335e-02, -4.911842e-02, -5.081842e-02, -2.875742e-02],\n",
      "        [ 3.556728e-02, -5.545589e-02,  4.708000e-02,  6.627212e-02,  6.969262e-02,  1.538642e-03,  3.577124e-02, -5.163842e-02,  6.306130e-02,  2.719235e-02,  4.393522e-02, -3.743281e-02,\n",
      "          1.295335e-02,  5.337289e-02,  6.894418e-02,  4.438289e-02,  5.827861e-02, -4.580766e-04, -1.793594e-02,  1.429909e-02,  4.555658e-02,  2.660512e-02, -1.922369e-02, -5.283768e-02,\n",
      "          1.667164e-03,  5.182503e-02, -4.592275e-02, -3.479685e-02, -2.422996e-03, -6.688019e-02, -6.476296e-02,  6.112208e-02, -2.250862e-02,  6.169321e-02, -5.848334e-02,  3.389702e-02,\n",
      "          5.654305e-03, -3.214001e-02, -6.944360e-02, -3.307769e-02,  6.582063e-02, -5.021064e-02,  4.487342e-02,  5.224827e-02,  6.272713e-02, -7.013322e-02,  5.086356e-02,  5.608471e-02,\n",
      "         -6.392100e-02, -5.216286e-03,  4.800278e-02, -2.503701e-02,  6.317314e-02, -4.522994e-02, -4.838035e-04,  4.966285e-02,  3.222600e-02,  6.599929e-02,  2.023857e-02,  5.672134e-02,\n",
      "         -2.099097e-03, -4.988808e-02, -3.764674e-02,  1.522761e-02,  6.594830e-02,  4.038832e-02,  6.484499e-02,  4.634472e-02, -5.675099e-02, -6.287467e-02, -1.499452e-02,  5.738296e-02,\n",
      "          2.508134e-02,  3.289282e-03, -5.644693e-02,  4.014107e-02,  6.756223e-02,  5.297050e-02,  6.855405e-02, -4.570709e-02, -1.292869e-02, -3.029438e-02, -3.388898e-02,  4.952942e-02,\n",
      "         -3.262501e-02, -6.051185e-02,  1.479986e-02,  5.302929e-02,  3.835998e-02, -6.887545e-02, -7.260233e-03, -5.546066e-02,  2.582049e-02, -4.022109e-02,  5.971903e-02, -2.371002e-02,\n",
      "         -5.909277e-02,  4.152806e-02,  4.226588e-02,  5.976325e-02, -6.799492e-02,  3.457523e-02, -5.110843e-02,  3.921241e-02,  4.534212e-02,  2.091125e-02, -3.970682e-02,  4.796413e-02,\n",
      "         -5.825841e-02,  6.557310e-02, -2.983236e-02,  5.340821e-02,  1.606974e-02,  1.862843e-02,  1.381321e-02,  3.788567e-02, -6.700291e-02,  6.461874e-03,  5.923351e-02,  5.182953e-02,\n",
      "         -9.297814e-03, -3.730774e-02, -1.947857e-03, -5.229565e-02,  2.454475e-03,  6.336943e-02, -4.983874e-02,  4.033074e-02, -5.878975e-02,  1.032890e-02, -8.868709e-03,  2.571455e-02,\n",
      "         -4.995375e-02,  2.787793e-02,  2.681424e-02,  2.697811e-02, -6.634727e-02,  2.679890e-02,  6.391197e-03, -3.435415e-02, -5.381221e-02,  6.700081e-02, -6.575614e-02, -6.922523e-02,\n",
      "         -4.125517e-02,  4.991592e-02,  3.441352e-02,  1.644591e-02, -4.125499e-02, -2.730241e-02, -1.629487e-03,  6.282475e-02, -2.756721e-02,  4.107179e-02,  5.108665e-02, -3.536265e-02,\n",
      "         -1.675883e-02,  1.534519e-02, -4.121251e-02, -7.125653e-03, -3.864432e-02,  5.557909e-02,  6.838761e-03,  1.346253e-03,  6.342789e-02, -2.073653e-03, -2.803777e-02, -1.287260e-02,\n",
      "          5.410991e-02, -1.574474e-02, -7.019185e-02,  6.758281e-02,  3.757328e-04, -5.436403e-02, -5.874657e-02, -1.378827e-03, -1.169806e-02, -1.837167e-02,  3.498718e-03, -3.245565e-02,\n",
      "         -5.074874e-02, -3.883800e-02,  3.177840e-02,  4.679462e-02,  6.227667e-02,  3.601341e-02, -4.241191e-02,  6.006751e-02, -6.326251e-02,  6.545953e-02, -2.894733e-02, -1.616286e-02,\n",
      "          2.947595e-02, -5.008261e-02,  1.937674e-02, -4.269227e-02, -3.713190e-02, -1.224418e-02, -1.770970e-02,  2.905965e-03],\n",
      "        [-2.149257e-02,  1.353994e-04, -4.252287e-02,  2.960473e-02, -1.171054e-02, -8.871239e-03,  1.898271e-02,  1.952755e-02,  5.638249e-03, -5.233291e-02, -1.813652e-02,  5.095213e-02,\n",
      "          1.856827e-02, -1.514292e-02,  3.847780e-02,  1.480864e-02, -4.593547e-02, -3.824377e-02,  5.435757e-02, -1.656544e-02,  1.411051e-03,  6.706799e-02, -5.353443e-02, -1.174682e-02,\n",
      "         -1.549050e-04,  2.354184e-02, -1.235423e-02, -1.989383e-02,  6.912740e-02, -1.867983e-02,  8.389510e-03, -5.120603e-02,  7.951647e-03,  5.656780e-02, -6.768705e-02,  3.376439e-02,\n",
      "          5.726867e-02, -4.805833e-02,  1.829458e-02,  6.870272e-02,  1.556975e-02, -6.239459e-02, -6.447470e-02,  5.078645e-02,  3.635193e-02,  4.882057e-02,  6.177349e-02, -3.271425e-02,\n",
      "          9.484299e-03,  5.260086e-02, -5.416570e-02,  6.576154e-02, -2.392307e-03,  2.354221e-02, -1.142770e-04,  6.177350e-02,  5.483625e-02, -6.278480e-02, -6.545004e-02, -9.553824e-03,\n",
      "          2.938085e-02, -1.164130e-02,  3.270561e-02,  5.789883e-02,  2.495138e-02,  5.360944e-02, -2.588015e-02,  2.527201e-02,  2.021632e-02, -6.536027e-02, -5.019359e-02,  6.815914e-02,\n",
      "          7.641390e-04, -5.388760e-02,  5.896544e-02,  6.119402e-02,  2.162037e-02,  3.757702e-02, -4.692544e-02,  5.325718e-02, -3.646088e-02, -6.756969e-03,  4.075617e-04,  6.891833e-02,\n",
      "         -4.021426e-02,  1.794025e-04, -3.525690e-02,  8.618288e-03,  1.115404e-02,  1.473182e-02,  6.069406e-02, -6.869640e-02, -1.446224e-02,  6.294153e-02,  1.662107e-02,  9.334855e-03,\n",
      "         -3.306473e-02, -6.333812e-02, -6.778951e-02, -5.791545e-02, -3.559981e-02,  4.874366e-02, -1.011067e-02,  5.057272e-02,  2.707428e-02, -5.931152e-02, -6.620575e-02, -4.558581e-02,\n",
      "          6.866204e-02,  4.141243e-02,  6.015439e-02, -1.946948e-02, -5.792989e-02,  4.867356e-02, -1.064900e-02, -3.631791e-02,  2.670990e-02,  4.397114e-02, -4.666168e-02, -6.025793e-02,\n",
      "          1.929693e-03, -2.508513e-02, -5.694006e-02, -3.662623e-03, -1.628233e-02,  6.587618e-02, -1.153384e-02,  4.453471e-02, -1.510451e-02, -8.515250e-03, -1.322843e-02,  5.101430e-02,\n",
      "         -4.216772e-02, -3.359750e-02, -5.895592e-03,  1.795769e-02, -6.207834e-02,  3.057260e-02,  3.552424e-02,  3.853837e-02,  3.853068e-02, -4.877910e-02,  6.351844e-02, -4.004561e-02,\n",
      "          4.375748e-03, -7.650122e-03,  2.598280e-02, -1.058842e-02, -1.620360e-03, -5.873317e-02,  2.753856e-02, -2.088960e-02,  5.428942e-02, -6.866141e-02,  6.412054e-02,  7.734150e-04,\n",
      "         -9.352073e-03,  5.549420e-02, -7.232271e-03,  7.005572e-02, -2.739748e-02, -6.067657e-02,  6.549185e-02,  8.310914e-03,  4.570564e-02,  3.003667e-02, -2.043795e-02,  1.816882e-02,\n",
      "          4.319804e-02,  5.802234e-02, -1.451816e-02, -6.593996e-02,  3.127895e-02,  3.044295e-02, -4.203435e-02,  1.745375e-02,  4.294477e-03,  5.637451e-02, -4.006558e-02, -5.899838e-02,\n",
      "          1.410762e-02,  2.637789e-02, -5.919486e-02, -2.516862e-02, -4.004164e-02,  5.614758e-02, -3.727424e-02,  1.422390e-02,  3.695408e-02, -6.071890e-02,  6.264576e-02,  2.072626e-02,\n",
      "          4.858370e-02,  8.198269e-03,  3.170228e-02,  6.143438e-02, -6.434322e-02, -3.335992e-02, -3.535118e-02, -4.430704e-03],\n",
      "        [-3.019830e-02,  1.410018e-02, -6.737766e-02,  4.619170e-02,  3.811470e-02, -3.803331e-02,  1.953810e-02, -3.693423e-02,  6.734212e-02,  7.007010e-02, -7.223062e-03, -5.590719e-02,\n",
      "         -3.998840e-02, -6.618231e-02,  3.550591e-02, -3.346172e-02,  8.976370e-03,  5.234684e-02, -4.774179e-02, -4.929843e-02,  7.059517e-02, -5.496264e-02,  1.593538e-02, -5.344295e-02,\n",
      "         -2.032697e-02,  6.859227e-02, -5.474597e-03, -3.501922e-04,  5.148720e-02,  1.728062e-02, -2.975103e-02,  3.805036e-02, -6.497571e-02, -5.235869e-02, -6.996943e-02, -3.932245e-02,\n",
      "          2.430863e-02, -3.563103e-02,  1.985442e-02, -7.016199e-02,  4.695766e-02,  5.413687e-02,  2.905802e-02,  9.603225e-03,  4.743288e-02,  5.289438e-02, -3.395049e-02,  6.776889e-02,\n",
      "          3.120025e-02,  6.215014e-03,  3.733471e-02, -1.890401e-02,  1.559513e-02, -8.972064e-04,  3.161408e-02, -1.073540e-02, -3.050008e-02,  3.700740e-02,  5.522818e-02, -4.854679e-03,\n",
      "          3.809676e-02,  5.296919e-02, -7.266462e-03,  3.524895e-02, -2.001273e-02, -6.252594e-03, -6.648090e-02, -6.748360e-02, -3.409892e-02, -2.604008e-02, -3.381844e-02, -6.426372e-03,\n",
      "          3.319198e-02, -6.578848e-03,  2.728345e-02,  2.274065e-02,  5.727042e-02, -3.818549e-03, -2.690431e-02,  3.966500e-02,  3.771092e-02, -2.859242e-02,  6.820176e-02, -6.554133e-02,\n",
      "         -4.992326e-02, -6.259593e-02,  6.368177e-02, -2.711367e-02,  6.719003e-02, -9.851903e-03,  2.374113e-03,  6.704956e-02,  3.429070e-02,  1.021414e-02, -5.155285e-02, -8.372042e-03,\n",
      "          4.265092e-02,  3.929774e-02, -6.678283e-03,  4.071397e-02, -9.556748e-03,  1.428449e-02, -9.030107e-03, -1.716708e-02, -1.450399e-02,  3.273322e-02,  3.324825e-02,  3.100479e-02,\n",
      "          2.335028e-02, -6.857824e-02,  4.319559e-02,  3.335961e-02, -3.499844e-02, -5.713164e-02,  5.785709e-02, -3.940585e-02, -5.667031e-02, -9.606659e-03, -6.889876e-02,  8.340321e-03,\n",
      "         -4.262169e-02,  6.211170e-02,  3.396615e-02, -2.803279e-02,  6.375230e-02,  6.812499e-02,  3.330665e-02, -6.093304e-02, -6.015662e-02, -5.048811e-02,  5.417767e-02,  1.210456e-02,\n",
      "         -6.759155e-02,  1.432087e-02,  3.339791e-02, -2.477071e-02, -5.223540e-02,  2.303923e-02, -3.213530e-02, -5.915777e-02, -2.564687e-02,  3.658939e-02, -4.913083e-02,  1.127242e-02,\n",
      "         -2.913308e-02, -1.728554e-02, -1.810309e-02, -4.565954e-02, -6.231287e-02, -2.172500e-02, -2.846035e-02,  9.053871e-03, -1.620904e-03, -3.160816e-02, -3.237278e-02, -6.182247e-02,\n",
      "          2.541526e-02, -3.861842e-02, -2.591028e-02,  5.736711e-02, -5.854923e-02,  6.847292e-03, -1.543423e-02,  6.670907e-03, -6.215917e-02, -6.971701e-02, -4.435617e-02,  2.404090e-02,\n",
      "          4.441252e-02, -6.961855e-02, -3.620245e-02,  7.129654e-03,  2.253663e-02, -3.469410e-02,  4.541837e-02, -2.575548e-02,  3.253715e-02, -4.790778e-02,  5.124231e-02,  6.172181e-02,\n",
      "         -6.849765e-02, -7.959023e-03,  4.248556e-02, -3.642187e-03,  3.866327e-02,  4.599381e-02,  1.211107e-02, -6.734063e-02, -6.096028e-03, -2.887871e-02,  8.229166e-04,  3.050108e-02,\n",
      "         -4.135486e-02, -2.805920e-02,  3.482760e-02,  1.191963e-02,  6.209166e-02,  3.179336e-02,  1.355100e-02,  5.045980e-04],\n",
      "        [ 3.077880e-02, -2.175815e-02,  3.321599e-02, -5.758882e-02, -1.728178e-02, -6.551470e-02,  4.558053e-02, -5.969480e-02, -9.748820e-03, -3.737488e-02,  5.564908e-02, -3.575534e-02,\n",
      "          3.719785e-02, -7.590897e-03, -1.053998e-02,  4.748737e-02, -5.637180e-02, -4.048633e-02,  2.104414e-02, -6.497057e-02, -2.994015e-02, -2.144568e-02, -1.705438e-03,  2.802253e-03,\n",
      "         -2.966970e-02, -1.977476e-02,  3.821388e-03, -2.065644e-02,  3.644897e-02,  5.707064e-02,  5.939972e-02, -4.995896e-02,  5.041274e-02, -4.569238e-02,  4.103264e-02,  2.884112e-02,\n",
      "          1.171543e-02,  1.555610e-02,  6.469607e-02, -3.964408e-02,  4.346342e-02,  9.629652e-03,  3.883246e-02,  3.526155e-02,  9.740397e-03,  2.831360e-02,  1.990870e-04,  2.151927e-02,\n",
      "         -2.678417e-02, -5.325604e-02, -4.855091e-02,  2.317805e-02, -3.997706e-02,  6.489342e-02,  4.031133e-02, -6.736139e-02, -4.378651e-02, -1.266780e-02,  3.392401e-02, -5.936615e-03,\n",
      "         -4.499162e-02, -2.843857e-02,  1.236878e-02,  1.416317e-02, -1.167391e-02, -1.620493e-02, -5.815680e-02,  2.153830e-02,  3.129137e-02,  1.016902e-02, -6.552406e-03,  4.125438e-02,\n",
      "          5.305531e-02,  1.486982e-02, -5.354755e-03, -6.768572e-02,  3.940074e-02, -7.052433e-02,  6.001458e-02, -6.217835e-02, -3.368785e-02,  3.359340e-03, -6.560171e-02, -2.108109e-02,\n",
      "         -2.839113e-02, -4.504570e-02, -6.450931e-02,  6.430410e-03, -8.784711e-03,  2.681352e-02,  3.760036e-02,  6.476755e-02,  3.332423e-02,  2.696033e-02, -3.789008e-02, -6.304565e-02,\n",
      "          1.344530e-02,  1.007447e-02, -3.287373e-02, -5.722776e-03, -3.285649e-02, -5.411587e-02, -4.485062e-02,  3.441346e-02,  1.803597e-02,  1.587769e-02,  2.059102e-02,  3.190562e-03,\n",
      "          4.923069e-02, -5.216628e-02,  4.464957e-02, -7.385463e-04, -2.534045e-02, -5.601657e-02, -4.982455e-02,  2.472498e-03,  3.363641e-02, -5.801795e-02, -1.883996e-02, -1.569378e-02,\n",
      "          4.043221e-02, -6.140293e-02,  3.466469e-02,  2.500986e-02,  5.413701e-02, -6.920549e-02, -1.348918e-02,  3.461465e-02,  7.016773e-02, -4.723499e-02, -3.806383e-02, -8.943841e-03,\n",
      "         -4.689049e-02,  3.405725e-02, -5.380399e-02,  4.563700e-02, -4.310868e-02, -8.483410e-03, -3.028072e-03,  6.954291e-02,  5.611304e-02, -5.084125e-02,  2.789334e-02, -4.214104e-02,\n",
      "         -2.587438e-02, -6.436877e-03,  4.210713e-02, -1.224615e-02, -3.756635e-03,  4.434882e-02, -3.150968e-02, -3.876837e-02, -3.176442e-02,  5.183320e-02, -6.848754e-02,  2.718766e-02,\n",
      "         -2.594292e-04,  1.927643e-02,  4.675439e-02, -5.018053e-02,  4.865874e-02, -1.943234e-02,  1.181904e-02,  3.945068e-02,  2.311353e-02, -2.343544e-02,  4.454407e-02, -5.358314e-02,\n",
      "         -6.183907e-02,  3.418212e-02, -3.846525e-02, -2.742152e-02, -2.953783e-03,  1.600895e-02,  9.089716e-03,  4.859358e-02,  1.924606e-02,  3.254652e-02, -3.447307e-02,  6.670120e-02,\n",
      "          6.581444e-02,  2.695648e-02, -5.911139e-02, -6.866494e-02,  6.833435e-02,  5.400352e-03,  6.395299e-02,  2.609841e-02, -1.223618e-02, -3.905603e-02, -6.551541e-02, -5.548867e-02,\n",
      "          6.311998e-03,  3.707017e-02, -1.225936e-02, -3.136060e-02, -2.780537e-02,  2.967264e-02,  2.928342e-02, -5.102158e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.027709,  0.042218, -0.063396, -0.052104, -0.061415, -0.034603,  0.050273, -0.032538, -0.038449,  0.015396], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 設置 PyTorch 的輸出選項\n",
    "torch.set_printoptions(threshold=10000, precision=6, linewidth=200)\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    # __init__ 方法中，定義了模型的結構\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        # linear1 是一個輸入大小為 100，輸出大小為 200 的全連接層。\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        # ReLU 是一種常用的非線性激活函數。\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        # linear2 是一個輸入大小為 200，輸出大小為 10 的全連接層。\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        # Softmax 是一種常用於多分類任務的函數，用來將輸出轉換為概率分佈。\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "    \n",
    "    # forward 方法定義了模型的前向傳播過程；輸入數據如何依次通過各層，最終產生輸出。\n",
    "    def forward(self, x):\n",
    "        # 數據首先經過 linear1 層，再經過 ReLU 激活，接著經過 linear2 層，最後經過 Softmax 層。\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel() # 創建一個 TinyModel 實例\n",
    "\n",
    "print('The model;')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "# 循環會遍歷並印出模型中的所有參數（即 linear1 和 linear2 的權重和偏置）。\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "# 會遍歷並印出 linear2 層中的所有參數。\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Common Layer Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**線性層;全連接層 (Linear Layer)**\n",
    "\n",
    "The most basic type of neural network layer is a linear or fully connected layer. This is a layer where every input influences every output of the layer to a degree specified by the layer's weights.If a model has m inputs and n outputs, the weights will be an `m*n `matrix.  \n",
    "線性層的輸出可以表示為：`y = xW + b`，其中 `x` 是輸入，`W` 是權重矩陣，`b` 是偏置。For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.772721, 0.548795, 0.456000]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[-0.502086,  0.118776, -0.534763],\n",
      "        [-0.236756,  0.516878, -0.209722]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.316743,  0.322792], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[-0.883384,  0.327871]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2) # 創建一個全連接層，輸入大小為 3，輸出大小為 2。\n",
    "x = torch.rand(1, 3) # 創建一個大小為 1x3 的隨機數據。\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "# 印出 lin 層的權重和偏置參數。\n",
    "y = lin(x) # 將輸入 x 傳遞給線性層 lin，計算並返回輸出 y。\n",
    "print('\\n\\nOutput:')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這段程式展示了如何使用 PyTorch 定義和使用一個線性層。線性層是深度學習中非常重要的組件，它將輸入轉換為輸出，這個轉換是通過學習一組權重和偏置來實現的。在訓練過程中，這些權重和偏置會根據數據和損失函數進行調整，從而使模型能夠學習到數據中的模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do the matrix multiplication of x by the linear layer's weights, and add the biases, you'll find that you get the output vector `y`.\n",
    "\n",
    "One other important feature to note: When we checked the weights of our layer with `lin.weight`, it reported itself as a `Parameter` (which is a subclass of `Tensor` ), and let us know that it's tracking gradients with autograd. This is a default behavior for `Parameter` that differs from `Tensor`.\n",
    "\n",
    "Linear layers are used widely in deep learning models. One of the most common places you'll see them is in classifier moels, which will usually have one or more linear layers at the end, where the last layer will have n outputs, where n is the number of classes the classifier addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolutional Layers**\n",
    "\n",
    "Convolutional layers are built to handle data with a high degree of spatial correlation. They are very commonly used in computer vision, where they detect close groupings of features which the compose into higher-level features. They pop up in other contexts too - for example, in NLP applications, where the a word's immediate context (that is, the other words nearby in the sequence) can affect the meaning of a sentence.\n",
    "\n",
    "We saw convolutional layers in action in LeNet in an earlier video:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 卷積層：卷積層主要用於處理具有高度空間相關性的數據。它們在計算機視覺中非常常見，因為它們可以檢測圖像中相近特徵的組合，然後將這些組合構成更高層次的特徵。\n",
    "* 計算機視覺中的應用：在圖像處理中，卷積層用於識別邊緣、角落等低層次特徵，並逐步組合成複雜的形狀或物體。\n",
    "* 自然語言處理中的應用：在 NLP 中，卷積層可以用來檢測詞語的上下文（即序列中鄰近的詞語），從而影響句子的意思。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        # 第一個卷積層，接收 1 個輸入通道（灰度圖像），輸出 6 個通道，使用 5x5 的卷積核。\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        # 第二個卷積層，接收 6 個輸入通道，輸出 16 個通道，同樣使用 5x5 的卷積核。\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        # 全連接層，用於將卷積層的輸出映射到最終的分類結果上。\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120) # 輸入大小為 16*6*6，輸出大小為 120。\n",
    "        self.fc2 = torch.nn.Linear(120, 84) # 輸入大小為 120，輸出大小為 84。\n",
    "        self.fc3 = torch.nn.Linear(84, 10) # 輸入大小為 84，輸出大小為 10，對應於 10 個分類。\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window ; 進行 2x2 的最大池化，減少空間維度。\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2, 2)) # 對輸入進行卷積，然後應用 ReLU 激活函數來引入非線性。\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x)) # 將卷積層的輸出展平為一維，以便輸入到全連接層。\n",
    "        # 全連接層傳遞:\n",
    "        x = F.relu(self.fc1(x)) # 將展平的張量依次傳遞到全連接層中，並應用 ReLU 激活。\n",
    "        x = F.relu(self.fc2(x)) # 將展平的張量依次傳遞到全連接層中，並應用 ReLU 激活。\n",
    "        x = self.fc3(x) # 最後一層沒有激活函數，輸出最終的分類結果。\n",
    "        return x\n",
    "\n",
    "    # 計算展平的特徵數\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension，取出所有維度大小，除了批次維度。\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down what's happening in the convolutional layers of this model. Starting with `conv1`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**遞迴層（Recurrent Layers）**\n",
    "Recurrent neural networks (or RNNs) are used for sequential data - anything from time-series measurements from a scientific instrument to natural language sentences to DNA nucleotides. An RNN does this by maintaining a hidden state that acts as a sort of memory for what it has seen in the sequence so far.\n",
    "\n",
    "The internal structure of an RNN layer - or its variants, the LSTM (long short-term memory;長短期記憶) and GRU (gated recurrent unit;門控遞迴單元) - is moderately complex and beyond the scope of this video, but we'll show you what one looks like in action with an LSTM-based part-of-speech tagger (a type of classifier that tells you if a word is a noun, verb, etc.):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 通過維持一個隱藏狀態來記憶序列中的歷史信息，因此可以處理長序列中的依賴關係。\n",
    "\n",
    "LSTM(長短期記憶和) GRU（門控遞迴單元）是 RNN 的變體，專門設計來處理長期依賴問題。它們內部結構複雜，但可以有效地避免傳統 RNN 的梯度消失問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `embedding_dim`：詞嵌入的維度，即每個單詞的表示向量的大小。\n",
    "* `hidden_dim`：LSTM 隱藏層的維度，即隱藏狀態的大小。\n",
    "* `vocab_size`：詞彙表的大小，表示可處理的不同單詞的總數。\n",
    "* `tagset_size`：標籤集的大小，表示可能的詞性標籤的數量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # 詞嵌入層將單詞的索引轉換為對應的嵌入向量，這些向量將作為 LSTM 的輸入。\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        # 這些隱藏狀態包含了序列中已處理部分的上下文信息。\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        # 輸出每個詞對應的標籤得分。\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence) # 將輸入的句子（詞索引列表）轉換為對應的詞嵌入向量。\n",
    "\n",
    "        # 將詞嵌入向量傳遞到 LSTM 層中。\n",
    "        # view(len(sentence), 1, -1) 用來調整張量的形狀，以便 LSTM 能夠處理。\n",
    "        # LSTM 返回輸出隱藏狀態 lstm_out 和（可選的）隱藏狀態元組 _。\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "\n",
    "        # 將 LSTM 的輸出展平並傳遞給全連接層，生成對應於每個單詞的標籤得分。\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "\n",
    "        # 對標籤得分應用 Log Softmax 函數，得到每個標籤的對數概率分佈。\n",
    "        # 這些概率表示每個單詞屬於不同詞性標籤的可能性。\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor has four arguments:\n",
    "\n",
    "* `vocab_size` is the number of words in the input vocabulary.  \n",
    "    Each word is a one-hot vector (or unit vector) in a `vocab_size` -dimensional space.\n",
    "* `tagset_size` is the number of tags in the output set.\n",
    "* `embedding_dim` is the size of the embedding space for the vocabulary.  \n",
    "    An embedding maps a vocabulary onto a low-dimensional space, where words with similar meanings are close together in the space.\n",
    "* `hidden_dim` is the size of the LSTM's memory.\n",
    "\n",
    "The input will be a sentence with the words represented as indices of of one-hot vectors. The embedding layer will then map these down to an `embedding_dim` -dimensional space. The LSTM takes this sequence of embeddings and iterates over it, fielding an output vector of length `hidden_dim`.\n",
    "The final linear layer acts as a classifier; applying log_softmax () to the output of the final layer converts the output into a normalized set of estimated probabilities that a given word maps to a given tag.\n",
    "\n",
    "If you'd like to see this network in action, check out the Sequence Models and LSTM Networks tutorial on pytorch.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformers**\n",
    "\n",
    "Transformers are multi-purpose networks that have taken over the state of the art in NLP with models like BERT. A discussion of transformer architecture is beyond the scope of this video, but PyTorch has a `Transformer` class that allows you to define the overall parameters of a transformer model - the number of attention heads, the number of encoder & decoder layers, dropout and activation functions, etc. (You can even build the BERT model from this single class, with the right parameters!) The `torch.nn.Transformer` class also has classes to encapsulate the individual components ( `TransformerEncoder`, `TransformerDecoder` ) and subcomponents (`TransformerEncoderLayer`, `TransformerDecoderLayer` ). For details, check out the documentation on transformer classes, and the relevant tutorial on pytorch.org.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers 是一種多功能神經網絡架構，PyTorch 提供了 Transformer 類，允許用戶定義 Transformer 模型的整體參數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Other Layers and Functions**\n",
    "\n",
    "**Data Manipulation Layers**  \n",
    "There are other layer types that perform important functions in models, but don't participate in the learning process themselves.\n",
    "\n",
    "**Max Pooling（最大池化）** (and its twin, min pooling) reduce a tensor by combining cells, and assigning the maximum value of the input cells to the output cell. (We saw this) For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.321914, 0.236021, 0.430655, 0.152097, 0.727925, 0.819373],\n",
      "         [0.189953, 0.555486, 0.326744, 0.420363, 0.899552, 0.278097],\n",
      "         [0.635880, 0.267926, 0.274840, 0.070747, 0.850823, 0.829280],\n",
      "         [0.861568, 0.032475, 0.625679, 0.645713, 0.297683, 0.643696],\n",
      "         [0.359585, 0.745571, 0.288882, 0.101304, 0.324211, 0.133364],\n",
      "         [0.377945, 0.392677, 0.404468, 0.876196, 0.180975, 0.120142]]])\n",
      "tensor([[[0.635880, 0.899552],\n",
      "         [0.861568, 0.876196]]])\n"
     ]
    }
   ],
   "source": [
    "# MaxPool2d(3) 將 6x6 的輸入張量分割成 3x3 的區域，並對每個區域取最大值。\n",
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look closely at the values above, you'll see that each of the values in the maxpooled output is the maximum value of each quadrant of the 6x6 input.\n",
    "\n",
    "**Normalization layers** re-center and normalize the output of one layer before feeding it to another. Centering the and scaling the intermediate tensors has a number of beneficial effects, such as letting you use higher learning rates without exploding/vanishing gradients.\n",
    "\n",
    "重新中心化並歸一化一個層的輸出，再將其作為另一層的輸入。這可以防止梯度爆炸或消失的問題，並讓你在訓練過程中使用更高的學習率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.667809,  5.411770, 17.922087, 11.226503],\n",
      "         [14.156848, 14.394440, 15.735331,  7.223950],\n",
      "         [ 6.784162, 17.811817,  7.300866, 21.269615],\n",
      "         [15.609527, 17.357277, 22.560999,  9.459081]]])\n",
      "tensor(13.243255)\n",
      "tensor([[[-0.610756, -1.087662,  1.556901,  0.141518],\n",
      "         [ 0.385399,  0.456980,  0.860964, -1.703342],\n",
      "         [-1.021549,  0.709588, -0.940436,  1.252398],\n",
      "         [-0.136175,  0.237336,  1.349421, -1.450583]]], grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(1.490116e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5 # 對輸入張量進行了大幅度的縮放和偏移。\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "# 經過 Batch Normalization 層處理後，輸出的張量值被縮小並且集中在零附近，這有助於更好的學習效果。\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above, we've added a large scaling factor and offset to an input tensor; you should see the input tensor's `mean()` somewhere in the neighborhood of 15. After running it through the normalization layer, you can see that the values are smaller, and grouped around zero - in fact, the mean should be very small (> 1e-8).\n",
    "\n",
    "This is beneficial because many activation functions (discussed below) have their strongest gradients near 0, but sometimes suffer from vanishing or exploding gradients for inputs that drive them far away from zero. Keeping the data centered around the area of steepest gradient will tend to mean faster, better learning and higher feasible learning rates.\n",
    "\n",
    "**Dropout layers** are a tool for encouraging sparse representations in your model - that is, pushing it to do inference with less data.\n",
    "\n",
    "Dropout layers work by randomly setting parts of the input tensor during training - dropout layers are always turned off for inference. This forces the model to learn against this masked or reduced dataset. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.630955, 0.035210, 0.435472, 0.337215],\n",
      "         [0.239945, 0.074656, 0.800279, 0.892582],\n",
      "         [0.150856, 0.591368, 0.257231, 0.838336],\n",
      "         [0.893400, 0.000992, 0.684879, 0.894716]]])\n",
      "tensor([[[0.000000, 0.058684, 0.725787, 0.562025],\n",
      "         [0.000000, 0.124427, 1.333799, 0.000000],\n",
      "         [0.251426, 0.000000, 0.428719, 0.000000],\n",
      "         [0.000000, 0.000000, 1.141465, 0.000000]]])\n",
      "tensor([[[0.000000, 0.058684, 0.725787, 0.000000],\n",
      "         [0.399908, 0.124427, 1.333799, 0.000000],\n",
      "         [0.000000, 0.985613, 0.428719, 1.397227],\n",
      "         [0.000000, 0.000000, 1.141465, 0.000000]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) # 隨機的 3D 張量 my_tensor，其尺寸為 1×4×4。\n",
    "print(my_tensor)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4) # p = 隨機丟棄的概率\n",
    "\n",
    "#  Dropout 是隨機的，所以每次應用時輸出的結果會不同。\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you can see the effect of dropout on a sample tensor. You can use the optional p argument to set the probability of an individual weight dropping out; if you don't it defaults to 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation Functions**\n",
    "\n",
    "Activation functions make deep learning possible. A neural network is really a program - with many parameters - that simulates a mathematical function. If all we did was multiple tensors by layer weights repeatedly, we could only simulate linear functions; further, there would be no point to having many layers, as the whole network would reduce could be reduced to a single matrix multiplication. Inserting non-linear activation functions between layers is what allows a deep learning model to simulate any function, rather than just linear ones.\n",
    "\n",
    "`torch.nn.Module` has objects encapsulating all of the major activation functions including ReLU and its many variants, Tanh, Hardtanh, sigmoid, and more. It also includes other functions, such as Softmax, that are most useful at the output stage of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Functions**\n",
    "\n",
    "Loss functions tell us how far a model's prediction is from the correct answer. PyTorch contains a variety of loss functions, including common MSE (mean\n",
    "squared error = L2 norm), Cross Entropy Loss and Negative Likelihood Loss (useful for classifiers), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
